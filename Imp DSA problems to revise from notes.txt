Foundation 1
----------------

Arrays
--------

1) Bar Chart....best pattern question
2) Rotate an array by k places.....reverse parts then reverse whole
3) Subsets of Array....easier using recursion
4) Ceil and Floor......Application of binary search
5) First Index, Last Index......Application of binary search


2D Arrays
------------

1) Spiral Traversal....box k andar box se solve kro, innermost box might not have all walls.....count < tne in outer as well as inner loops
2) Rotate Matrix by 90 degree clockwise.....transpose given matrix then reverse each row...... Transpose me [i][j] ko [j][i] se swap karna hota h but this cannot be done for all i,j combinations.....only for half of total combinations...in which j>=i...j begins from i
3) leetcode 240 Search in a sorted 2D array/matrix 


Strings, String Builders, ArrayLists
------------------------------------------

1) Print all substrings....not using recursion
2) Print all palindromic substrings..........Brute force
3) String compression
4) String Interning and String Immutatbility; StringBuilder
5) Print all permutations of a string - iterative (Not at all intuitive).....divide by n then (n-1)....all the way to 1...divide kya? kaunsawa permutation and the subsequent quotients....jo jo remainder aate jata h remaining string me se usko nikalkar print krte rho
6) Remove primes from arraylist..........Conclusion: always remove elements from end of arraylist....taki shifting (due to deletion from mid arraylist) k wajah se garbar na ho jaye


Recursion
------------

1) Tower of Hanoi.....recursiveCall1(swap d, h) --> print (s, d) --> recursiveCall2(swap s, h) 
2) First Index, Last Index in array
3) All indices of array..........DIY without seeing solution (high chances of mistake in 1st attempt)
4) Get Subsequence.....understanding base case is imp
5) Get KeyPad Combination.......DIY if revised 4
6) Get Stair Paths....ek ek karke hi sirf to decrement nhi kar rhe  ==> n can become < 0 too in just 1 step.....when n<0 what to return from base case? empty list cuz no way to get to 0 stairs
7) Get Maze Path with Jumps..........DIY without seeing solution...mixture of get Stair Paths and get Maze Paths.....Good Problem for revision

8) Print Subsequence............ on way up...ans bnate chalo.....compare with "Get Subsequence" which is "on way down" soln
print wale sare using "on way up"....pass a param, ans bnate chalo.....to save space we do not follow "on way down"
get wale sare using "on way down"...... return something from node wala tarika

option could be include/exclude or include 1 among many

recursion is of two types
   1) on way down....tum jawab do hum apna jawab bnaenge.....root pe final ans milta h
   2) on way up...base case/leaf pe final ans milta h

9) Print stair paths.....path + 1 krne se kya hoga aur 1+ path krne se kya hoga ye socho  
10) Print Maze paths....notice the two ways...call smart, base case normal ......call stupid, base case smart.....bas ye call krne ka tareeka revise krwana tha notes me se....waise to question me dam nhi

11) Print permutations...sare characters ko starting character banne ka mauka dena hoga.......compare with "Print all permutations of a string - iterative" under Strings section
12) Print Encodings......DIY.........2 options - 1char, 2 char ko parse karna h sari possibilities bnane k liye .....2 char hona bhi chahiye pehle....aur wo bhi 2char >26 nhi hona chahiye
13) FloodFill...backtracking ka matlab apne footprints mita dena....par aisa krna hi kyu h? .....ya to previously exploration me ans nhi mila ya phir mil gya and aur bhi mil sakta h cuz multiple ans are possible.....understand visited array ka significance ...needed when we go in dir and 180 degree opposite dir as well..to prevent infinite loop visited array lena padta h.....understand why Red Euro symbol k jagah par return likhna kyu required h
  
By now I am wondering kab kab "on way up" use karna h aur kab "on way down"....kahin to notes me likha tha ye shayd...maybe level up k recursion ya DP me mil jaye.....TODO: mile to yahan likh dena reason

for now --> man me socho jisme recursiveAns se myAns bnana hard lge...usme "on way down" nhi use krna
  
14) Target Sum Subsets.....pehle subsets bna lo phir target se subsetSum compare kro.........baad me jab poora subset bn gya h tab jakar loop lgakar sum calculate krne se accha h ki jaise jaise "on way up" jate ho waise waise subsetSum calculate krte rho
15) N Queens.....Very Very Imp.....how solution thought from scratch all the way to its code

level - row - passed as param
option - which column of the current row (option for placing a queen)
 
if safe
then place a queen at that (row, col) ....chess[row][col] = 1....after recursive call has to be backtracked
and then check for next row....recursive call for row+1.....ans bnate chalo...row-col in string psf

safety check in 3 directions
from current row to above rows only (not below rows)
in 3 directions - north-west, north, north-east
 
16) Knights Tour

 
Stacks and Queues
-----------------------

1) Read from OOPS | Swap Game 3 onwards to just before start of Arrays and Queues section
2) Dynamic stack...using array.....create array of double size, change reference..........seems O(n) due to copying all elements of old array into new one...but push() even now is O(1)......dynamic me kabhi overflow msg print krne ki zaroort nhi pdti (same with dynamic queue as well.....front pointer humesha update krte hue chalna h)....tos pointer humesha update krte hue chalna h
 
Queue<> ke aur Stack<> ke alag alag se functions yaad rkhne se accha h always use ArrayList<> as stack or queue a/c to need

Stack<> --> push(), pop()
Queue<> --> add(), remove()
 
3) Normal Queue....two pointers front and back not needed....front, size is enough....note why need to use modulus.....X = (front + Y) % arr.length......observe the condition of display function loop....specifically what it should not be
4) Balanced Brackets....3 cases should be dealt #OB> #CB or #OB < #CB or inappropriate pair(jo bracket sabse baad me aaya h(open hua h) wo sabse pehle close honi chahiye)  
5) Duplicate Brackets....meaning of duplicate brackets smjhna is tricky.........we don't talk about duplicate brackets if the given expression is not balanced (Balanced Brackets).......when CB is encountered pop till OB............. agar CB se just pehle OB hi mil jaye ( no characters in between) ==> duplicate brackets

strategy: push everything in stack which is not CB then start popping and thinking

6) Celebrity Problem.....Very Imp....question padhkar bilkul nhi lagta ki ye stack problem ho sakta h...aur stack se kaise solve kar skte wo bhi itna zyada intuitive nhi..............Approach --> all possible celebrities ko stack me store rkho (initially sare k sare ko possible celebrity maankar stack me rakh do).... then 2 do krke pop kro aur ek possibly celebrity ko filter out kar do........ ye repeated filtering out tab tak krni h jab tak stack me bas 1 possible celebrity nhi reh jata....jo reh gya h wo bhi possible celebrity h confirm celebrity nhi ( there can be either 0 celebrity or only 1 celebrity...kind of like Saddle Point under 2D Arrays section)...to ab is possible celebrity par celebrity h ya nhi ka check phir lga do ......ye stack solution ka TC O(n) kaise h ye smjhna bhi zaroori h

7) Postfix Evaluation and Conversion....Imp type...Refer Prefix Evaluation and Conversion as well...direction of reading string  
note while converting to infix, brackets use krni h 

8) Infix evaluation .....Very Very Imp.....Interview me ye 100 % shi ho jaye matlab tum alag hi level pe ho

   - 2 stacks used 1) for operands 2) for operators and ')'
   - 4 cases bnta h ....what to do when encounter ......1) ')'       2) '('    3) operators 4) operands

        -- operands encountered while reading given infix expression L to R  --> push in operands stack ( ye operands later evaluation k liye use honge ....isliye have to take care of char to integer conversion)
        -- '(' encountered --> push in operators stack
        -- ')' encountered --> 1) pop and keep on evaluating until we get '('           2) pop '(' too
        -- operators encountered --> jab tak operators stack empty nhi ho jata ya jab tak operators stack ke top pe '(' nhi dikh jata ya jab tab operators stack ke top par current char se lower precedence(matlab agar barabar precedence hua tab bhi evaluate krwana h) (of course precedence check krne k liye ek alag function likhna pdega ) ka character nhi aa jata.............tab tak purane operators ko evaluate krwate rho aur result ko operands stack me daalte rho (Note: even after processing whole infix expression, operator stack might not be empty (ex: 2+3*6) to phir se evaluate then push result in operand stack krna pdega and at last we'll find result in top of operand stack)....usi k baad current operator ko stack me daal sakte

       Note: poore code me operators stack me se hi bas pop krte h kabhi kabhi....operands me se pop bas evaluate krte samay krte h varna nhi
 

9) Queue to Stack adapter - push efficient.......Imp type
    -- queue use krke stack bnana h
    -- 2 queues use karna pdega...mainQ, helperQ
10) Queue to Stack adapter - pop efficient .............DIY
11) Stack to Queue - add efficient...........slightly different from previous adapter questions...references mainS aur helperS ka interchange nhi karna h 

12) Next Greater Element to/on the Right ...NGOR

        In ans[] always store index of ans and not the ans(array element)
        
        main: NGOR
        derivatives: NGOL, NSOR, NSOL

        stack contains --> ifwahnbfy --> indices for which ans has not been found yet

        algo --> pehle dusro k bare me socho....stack me se tum(current ele) kis kis k ans ho   
                 phir khudke bare me.....mera ans bhi pta krna h...therefore put myself in stack

        OL --> traverse R to L.....every cell initiallised with -1 (direction is opposite cuz dusron k bar me Pehle sochte hue chlna h)
        OR --> traverse L to R......every cell initialised with n(=arr.length)

        NG --> arr[st.peek()] < arr[i]
        NS --> arr[st.peek()] > arr[i]


    void NGOR (int []arr, int[] ans) {
       int n = arr.length;
       Arrays.fill(ans, n);

       Stack<Integer> st = new Stack<>();
       for(int i =0; i<n; i++) {
          while(st.size() != 0 && arr[st.peek()] < arr[i]) { // note: while and not if
             ans[st.pop()] = i;
          }

          st.push(i);
       }
       
    }

13) Stock Span....it's basically i - NGOL[i]...stock span definition: no of days passed between today and 1st day before today where stock price was higher than today

14) Largest Rectangle/Area in Histogram.....Refer Level Up notes instead
        -- Approach 1 --> NSOR, NSOL used..........mutiple pass solution
            - width = NSOR - NSOL - 1
        -- Approach 2 (Imp...although most people don't know this) --> 1 pass solution ......... NSOR jab hume milta h to uska hum kaise use krte they in previous solution?.....to ye socho aur NSOR ka code hi likho....NSOL will be whatever is below me in stack (magnitudewise) cuz mere (current ele) se <= ko to hum stack se pop krwa dete h in NSOR..............Caution: for some bars we might not find NSOR...pehle aise cases n se initialise krne par handle ho jate they ....par yahan na hi hum NSOR[] array use kar rhe...aur initially bhi hum stack me -1(cuz we are storing NSOL actually in stack) daal rhe n nhi 
  
        -- T. C of Approach 1, 2 are same but approach 2 does it in less passes of given input array

15) Sliding Window Maximum
        -- Approach 1: monotonic stack (NGOR) - last NGOR within window is the maximum for that position of window
        -- Approach 2: monotonic deque

16) Merge Overlapping Intervals.....sort the (start, end) pairs. Obviously only adjacent ones can overlap. But someone can overlap with the result of the previous overlap as well like candy crush game. so basically we need to remember order. So we use stack. Push the smallest pair in the stack initially. If the next/current/incoming pair begins after whatever is on the top of stack has ended, then obviously no overlap else overlap. In case of overlap merge . This can be done by correcting the ending time of the top of stack pair with the max of the 2 ending times which we are comparing

17) Smallest Number Following Pattern ......... Very Unique....Might not remember
     
     sabse chota no when we use less numerical magnitude numbers at the most significant bits
     
     so let's assume that there are only i's...so the numbers will look something like 123456......
     i) we have to remember the last number so that we can know the next number 

    But now if we get 'd' we have to decrease the number.....so knowing just the last number is enough
    But what if there are multiple d's .....so we should remember previous numbers as well
    so basically we have to remember whichever order we have followed so far....so we can use stack


    Observation through dry run on multiple examples --> smallest number tabhi aaega pattern follow karte hue jab hum D ke sequence k around filling Right to Left kare and not the other way round
    
   Solution --> i) stack me push aur ii) number increment to  humesha karna h chahe D aaye ya I ( number 1 se start karna pdega cuz MSB me less and less magnitude chhaiye)
                    par jab I aaye to stack empty bhi karna hoga kyunki ho sakta h I ke baad phir se D ka sequence aane lage in which case we might require opposite ordering from R to L. Therefore stack as LIFO
   Caution...Edge case --> only 'i' or only 'd' as string imagine krke dekho

- when I is encountered tab jo krna hota h that is even done outside the loop when all the characters have been read

18) Min Stack - min in O(1) time......apart from normal stack (kyunki baki functions abhi bhi btana h and that too in O(1) time), 1 more stack to store just mins .........EASY

19) VVV Imp - Min Stack - min in O(1) time and O(1) space.....NOT STRAIGHTFORWARD....problem 18 me hum sare min values yaad rakh rhe they in a stack....abhi O(1) space me problem (problem is..O(1) time me min btana h) solve karna h matlab stack nhi use kar sakte...stack nhi use karna h aur sare previous min values bhi yaad rakhne h par kaise...min to har incoming element k sath change nhi hoga...to kyun nahin 
       
      - use a variable 'min' instead of stack                                        
      - just remember the points of changes in min value. How?
      - instead of incoming element (V) we always store (V + (V-M)) in stack when V is < M(current min)
      - how we will be able to identify that at which places we have not actually stored V ,......for such places element in stack will be < M else not
      - jb ye pop krne ki bari aayi to hum stack se to pop kr denge pr usse (V) pehle min kya tha (M) wo pta kaise chlega
           tos = 2V - M (tos: top of stack)
           => M = 2V - tos 
           .....aur humne to V min me store krlia tha so..
           => M = 2min - tos
           => new min = 2 * old min - tos

      - Caution: V ke jagah 2V + (negative no) store kar rhe to overflow ka issue aa sakta h. Thus have to use long type and it's wrapper class Long........       .intValue() to convert Long to int.....leetcode 155

20) Two stacks in same array.....tos1 = -1, tos2 = n initially


Linked List (Foundation 1 + Level Up 2)
--------------
Advantage : to access non-contiguous locations in fragmented memory LL was introduced. Being able to access such locations is the advantage of LL
Disadvantage over array : i) extra memory required to store address................ ii) to get to any node have to travel through other nodes

removeLast() ....O(n)
removeFirst().....O(1)
addFirst()...........O(1)
addLast()...........O(1)


most common edge case ---> to be solved even before starting logic of problem........what if 0 child , what if 1 child
whether it is needed or not always use the below case
if(head ==null || head.next == null) return head;

Always dry run a LL problem before submitting for below cases
1) 0 length
2) 1 length
3) 2 length
4) odd length
5) even length

always use curr to iterate .....ListNode curr = head;



1)mid of LL....slow, fast pointer
   -- when even number of nodes and 
         - we want left node as mid.......stopping condition of loop.....fast.next != null && fast.next.next != null....preferred condition for breaking LL at mid
         - we want right node as mid.......stopping condition of loop.....fast != null && fast.next != null     .....also works for odd number of nodes 
         - return slow
         - Try not to blindly memorise this....draw and code
   -- when odd number of nodes (Note: condition same as even number of nodes and when we want right node as mid)
         - fast != null && fast.next != null

2) Kth node from end of LL.....size() directly ya indirectly (khud se size implement nhi kr skte) use nhi kar sakte
    - create initial separation of k then move the pointers with same speed.....near, far pointer.....far ko null tak nhi pahunchne dena h (have to keep within LL).....therefor have to use far != tail.....cuz tail ka next null hota h
    - challenge was to do this in 1 pass
3) Merge two sorted LL....remember T.C = O(m+n) not O(min(m, n))
    - compare and put in "res LL".....O(n) space
    - O(1) space (No extra space) solution in Level Up 2
        - ListNode dummy = new ListNode(-1);
        - ListNode prev = dummy
        - eventually ListNode head = dummy.next and dummy.next = null
        - 'dummy node' is used so that the same general code can be applied to every node including head. Also it helps in reducing NPE when we need to maintain prev. Also we don't have to worry about what will be the head of the result LL, it'll always be dummy.next
4) Merge K sorted Lists....Level Up 2
   - Approach 1: pick 2, merge and so on .... T.C: O(Nk) ....N=lk = total no of nodes in k LLs
   - Approach 2: connect LLs, sort list...O(NlogN)
   - Approach 3: Recursion (Divide and conquer)...break at mid...mergeTwoLists(recursive call1, recursive call 2).....O(Nlogk) // remember TC
   - Approach 4: using PQ  O(Nlog k)....also in HM and Heaps notes (Foundation 2)
5) Odd Even LL/ segregate 0,1/ segregate 0,1,2
    - collect odd nodes in a separate LL and even in separate LL then combine them.......also handle if all odd in input ....or all even in input.....O(n) space solution
    - O(1) space (No extra space) solution in Level Up 2
        - ListNode evenDummy = new ListNode(-1);        ListNode oddDummy = new ListNode(-1); 
        - ListNode evenPrev = evenDummy;                ListNode oddPrev = oddDummy;       

we swap nodes when it is array and not LL problem
In segregate 0, 1, 2
   - return zeroDummy.next but before that
   - don't do
       - prevZero.next = oneDummy.next then prevOne.next = twoDummy.next then prevTwo.next = null
   - do
       - prevOne.next = twoDummy.next then prevZero.next = oneDummy.next then prevTwo.next = null
   - so that we get the correct ans for when LL is only 2s   2-> 2-> 2-> 2-> 2

whenever we have to collect nodes, we use 'dummy' node

6) Reverse LL (Pointer Recursive)
7) Intersection Point of 2 LL.......using map is not allowed......
   - Approach 1: like "Kth node from the end of LL" problem, we'll have to create initial separation of diff in LL size in the larger LL
   - Approach 2 (useless...would take more time to code): attach tail of 1 LL to head of another then find starting node of cycle (Level Up 2)
8) Imp problem....Reverse nodes in group of K in LL  or K reverse in LL
    - Approach 1: create a LL to store reversed k nodes...O(n) space
    - Approach 2 (Level Up 2): O(1) space
         - maintain pointers: oh, ot, th, tt (o: original, t: temporary)
         - use curr.next = null and addFirst(curr, th, tt) to reverse k nodes
         - don't use custom reverse() cuz it changes head and tail

removeFirst(), addLast() --> queue
removeFirst(), addFirst() --> stack (for reversing order)

reverse linked list 2 leetcode 92....solve this too using oh, ot, th, tt pointers

9) Reverse a LL (data iterative)...Imp
10) Reverse a LL (data recursive)...Imp
11) Is LL a palindrome....using recursion like problem 9
    - recursive solution requires extra stack space
    - Moreover we should not solve LL question using recursion cuz stack size has a limit and max possible length of LL == total RAM available
    - for the same reason that array size has limit, we should not reduce LL problems to array problems (max possible length of an array = 2^31 - 1 as index of array is an integer  
    - if we have to do in O(1) space
        - break the LL in mid
        - reverse 2nd half of LL 
        - iterate over both halves and compare node by node
        - remember: after finding and restoring LL to as original is crucial
12) Fold a LL
- recursive solution in Foundation 1 but should avoid recursion for LL problems 
   - floor as param to know recursion depth....and then 2 conditions... 1) floor> LL size/2      2) floor == LL size/2
- break at mid
- reverse 2nd half
- some more logic


Tip: don't avoid using more pointers, functions in a LL problem

13) Unfold a LL(Level Up 2)
- in 1 pass of original LL make 2 sub LLs (sub LLs are not formed by dividing the original LL at mid; draw to find out how are the sub LLs should be formed)
- reverse the 2nd LL
- join at the end of 1st LL

- in fold we break at mid; but in unfold we don't break at mid

14) Add 2 LL.....Very Imp....DIY without seeing solution
    - Approach 1: using recursion and place value
    - Approach 2: using reverse() and dummy, prev to collect nodes of result
    - should usually avoid using recursion and reducing to array for a LL problem 
    - Practice Subtract 2 LL (Level Up 2)p....DIY without seeing solution

15) Multiply 2 LL (Level Up 2)....remember T.C: O(n*m) where n, m are length of the LLs.....multiply k LLs has  T.C. = O(N^2) for large k....N=kl=total number of nodes in k LLs
    - handling the addition of partial products is the most important
    - when two partial products are added no need to create new nodes for result instead modify nodes of old partial product

16) Quicksort LL (Level Up 2) ....If you can solve this w/o looking it up...you are in very good position
    - segregateOnPivotIndex() should return a list of 3 things...head of small, pivotNode, head of large
    - QS(), mergeSortedSubLists() should return list of {head, tail} so that merging of smaller subLLs can be easier


quicksort LL and multiply 2 LL are very good problems of LL


advantage of DLL over SLL: functions like addBeforeNode() is O(1) in DLL since we have prev, unlike SLL

17) LRU cache - easy but popular
   - Requirement: get(any), put() in O(1) in addition to LRU functionality
       - Candidates for get(), put() in O(1)
            - potential: stack, queue, HM (amortized O(1) and not actual O(1))
            - rejected: PQ, tree, graph, 
                        array (put() not in O(1) due to shifting of array), 
                        LL(get() not in O(1) unless we have node address and it's DLL i.e we've reference to prev node as well)
       - Candidates for LRU functionality (i.e maintain some sort of order)
            - potential: stack, queue, PQ(order not maintained but LRU can be fetched in O(1)), array, LL
            - rejected: HM, tree, graph
             
   - DS reqd: HM/Array + DLL (Java's LinkedHashMap is the same but it would make things too easy)
            - HM/Array to store the node addresses against the key to make get() possible in O(1)
            - HM is amortized O(1); array is pure O(1)
            - put() in array can be O(1) if instead of adding new node at a index we just update the value of the preexisting node if any
   - Whenever a node is touched even if it is just for get(), call makeRecent(node)

18) Copy List with Random pointers - Imp for interviews
    - Approach 1 (O(n) space) - HM <oldNode, newNode>
       - in 1st pass LL is cloned excluding random pointers
       - in 2nd pass random pointers are mimicked
    - Approach 2 (O(1) space - w/o using HM)... Imp
       - 1) zip new copied nodes with original nodes
       - 2) copy random pointers for copied new nodes
       - 3) unzip copied new nodes from original nodes

19) is cycle present in LL ?
- If slow and fast pointers meet after starting from the same node → cycle is present
- If they start from different nodes, they may still meet in an acyclic list (if speeds differ)
- So, pointer meeting alone isn’t conclusive — they must start from the same node to detect a cycle reliably

20) starting point of cycle in a LL (looks like un-intuitive but isn't)
   - find meeting point of slow and fast pointers with speed 1, 2 respectively
   - take two new pointers - one at head of LL, another at meeting point
   - now move the two pointers with same speed
   - wherever they meet is the ans node
   - Note: if we take any other speed other than 1, 2 to find the meeting point - this algo to find the starting point will not work
21) Find if cyclic LL has seq part too or not 
   - if SP = MP => no
22) Find cycle length
   - distance from head of LL to meeting point (for both completely cyclic LL and for hybrid LL)

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Foundation 2
----------------
 
Generic Trees
------------------
not two child like Binary Tree but has..... ArrayList<Node> children

1) Construct Generic Tree from given input............stack to be used
        - input me -1 dikha matlab we've got all info about a node ( ==> we now know about all the children of a particular node).....so that node should be popped out of stack (stack contains all the nodes about whom we do not have all the information i.e nodes whose all children are not known yet)
        - aur agar -1 k alawa kuch aur dikha to? ....to push to karna hi h stack me par tree bnate hue chalna h....i.e mai kiska baccha hu uske children[] me khudko add kar lena h before pushing in stack.............mai kiska baccha hu ye kaise pta chalega? mere se just pehle jo stack me hoga wo hoga mera baap ...kyu? cuz we are give preorder traversal of a GT ..which is N then L child then R child 
2) Height of GT.....max among height of all child + 1.......when we are talking in terms of edges(which is default) return -1 in base case or initialise with -1
    - if in terms of nodes then return 0 in base case or initialise with 0
3) Level Order Traversal of GT.....queue to be used....RPA....remove, print, add
4) Level Order - linewise  (each level in new line) 
    i) Solution1 ......2 queues....1 queue for current level, 2nd queue for nextLevel ....when mainQ is finished transfer the reference of childQ in mainQ
    ii) Solution 2.......null marker after every child of all the members of current level are pushed.....iski implemetation error prone h
    iii) Solution 3.......most used.....remove from queue till levelSize becomes 0 then newline then move to next level
    iv) Solution 4........store each child with its level....when the popped level is greater than the ongoing level we come to know that we have now entered next level
5) Level Order - Zigzag
    i) Solution 1....2 stacks (1 stack for current level, 2nd stack for nextLevel) + level variable (to find the direction in which we should iterate and push elements of children[] in childStack)
    ii) Solution 2.....1 stack + 1 queue + level variable
        - use LinkedList for both stack and queue

    matlab to bas 1 stack se hi h jisse order reverse ho jaye
6) Remove leaves in a GT
      - should remove from arraylist always from Right
      - ask first isLeaf()? to each node...if yes then remove it..................only then call the recursive function on each child
        Caution: can't call recursive call first on each child then ask each node that isLeaf()...........cuz in that case removing of child leaves might make parent a leaf which will get removed as now it has also become leaf and so on  the tree will become empty 
7) Linearize a GT...........DIY
     - breaks links of children from last .....cuz removal from last of arrayList does not create any problem
     - Caution....Imp...have to run the loop for node.children.size() > 1 and not node.children.size() != 1  ...............  cuz we have to run the loop for nodes with non-zero number of children and until the count becomes one....but node.children.size() != 1 allows the loop to be run even for leaf nodes which have 0 children

     - if faith is child ko linearise krke tail bhi bta de then it would be an efficient approach....as 1 loop will not be wasted in finding tail
8) Flatten BT to LL
   - Approach 1: recursive.... just like lineraize a GT (S.C. - O(n) recursion stack space)
   - Approach 2 (IMP): iterative (without using explicit stack)....O(1) space........DIY
9) LCA of 2 nodes
   - compute nodeToRootPath() for each node....then compare the paths from end of arraylist (from root) for 1st different node
10) Distance between nodes.....DIY..............note required nodeToRoot() required........(rootToNode() might also work....need to verify though)
   - distance != node1 to root to node2
     distance == node1 to LCA to node2
11) Are GTs mirror in shape(not datawise)?........DIY
   - Understand how it is different from ...Are trees similar in shape? (not datawise)
12) Is GT symmetric /foldable?
    - In other words, they are asking ..... is the given GT mirror image of itself?
13) Predecessor and Successor of given node in preorder traversal............Very Imp
    - have to find out both pre and succ in 1 pass itself
    - have to maintain a variable 'state'
    - next call krne se pehle predecessor ko update karna h........Note: ek child se dusre child k taraf jate waqt predecessor ko nhi update karna h.........predecessor to be updated in "Node Pre" not in "Edge Pre"
    - state 0 to state 1 --> matlab data mil chuka h aur isliye ab further traversal me predecessor update nhi karna....to further traversal karna hi kyu h? kyunki successor pta lgane k liye aage explore karna hi pdega...hum future nhi dekh sakte
    - state 1 to state 2 --> aur ek baar successor mil jaye to 'successor' ko bhi update nhi karna h in further traversals ..........Note: this is in addition to "predecessor ko bhi nhi update karna h" 

    - Caution: agar tree me data ho hi nhi to we might end up informing wrong predecessor....Edge Case.....han par successor me kuch galat nhi hoga....kyunki successor update hi nhi ho paya hoga
14) Ceil --> smallest among larger
    Floor --> largest among smaller

- We should initialise static variables just before using them cuz some other functions might also have changed them
- although we can declare them globally as instance variables
15) Diameter of GT....Very Imp
     - koi bhi node se 2 chiz return krwao...diameter across that node, height of that node
     - height of that node is required to calculate diameter across its parent
     - kyunki diameter of a tree represented by say root....can be across root or can be within any of its subtree
     - Refer Level Up 3 ....Diameter Set

     - or keep diameter static; calculate_Dia_Return_Height

16) Kth largest......Very Imp.....DIY  
     - equals floor of (K-1) th largest
     - 1st largest == floor of 0 th largest == Infinity

17) Iterative preorder and postorder traversal (external stack + state variable) ( this trick can also be used for inorder) (this trick can also be used for BTs) .......DIY for both GT and BT
      - 'state' variable used
      - stack has <--- elements which have not been explored completely yet
      - state = -1 (i.e if we found state = -1 in tos) => call to 0th child has not been made => pre area ....increment state to 0 so that 0th child can be called in next iteration
      - state = n ( n == number of children of the node in tos) ==> all the children have been explored => post area => time to pop
      - state = x in between [1, n-1] ==> call to (x+1)th child has not been made yet.....increment state to (x+1) so that (x+1) th child can be called in next iteration

18) Iterable and Iterator interfaces
     - both are interfaces
     - class which implements Iterable has to implement Iterator<Integer> iterator() function... the implementation should contain an object of a class which has implemented Iterator interface
     - class which implements Iterator has to implement hasNext() and next()
  

Binary Trees
----------------
possible edge cases ---> 0 child, 1 child (only L child, only R child), 2 child (both L, R child)...........2 child is the main problem and not the edge case

GT me for(Node child: node.children) se null handle ho jata h....BT me null ke liye if(node==null) {} wala check lgana pdta h

Whenever we want more than 1 information from any node we have 2 options.....i) club the multiple information into a class and return that from every node or ii) return the info which is required to calculate the answer for parent and keep other info as static variables which can be changed by every node

1) Construct BT from given input
    - for GT we have arraylist of children which is dynamic, so while processing input for GT we just need to know when the children list of a particular node has ended. That's why '-1' marker in input    
    - But for BT we do not have a list. Instead we have 2 nodes reference holders - L child and R child. So while processing input we need to know whether the node we are considering is the L child or the R child of the parent node
    - So in the input for constructing BT we use null for a non-existent child (it can be L or R child....if it is both then we use "null null" in input)...we'll always expect the first entry to be L child and next entry to be R child

    - to construct a BT from the input format described above, we use 'state' .....same logic as in iterative preorder of GT
    - state = 1 => next i/p is the L child of the node on tos(top of stack)
    - state = 2 => R child
    - state > 2 => both child of current node have already been plugged. Therefore time to pop the current node out of stack
 
2) Height of a BT.......when we are talking in terms of edges(which is default) return -1 in base case......height of leaf = 0 => height of null = -1
3) Iterative Pre, In, Post order traversal in BT (Note: Iterative not recursive)..........DIY for both GT and BT
    - on lines of iterative preorder, postorder traversal in a GT but not exactly same
    - here we have to check if L/R child exists in input only then push it in stack
4) Print K distance away......very Imp.........DIY
    -  this k distance can be k directly below me or .......1 up then k-1 down or......2 up then k-2 down.....up up up kab tak? all the way to root.......So first we need to find nodeToRootPath
    - traverse on nodeToRootPath[] and call recursive function on each of the node in it
    -                   A
                     /      \
                    /        \
                   /          \
                  C            B
                 
      Let's say we want to find 3 distance away from B.... 1 up to A then 2 down can be 1 way.... now when we go 2 down from A obviously we don't want to go towards B...cuz going 2 down from A towards B would be an equivalent of 1 down from B but we wanted 3 away from B
   - So we should mark B as 'blocker' node when we try to go down from A through initial recursive call.....when blocker node is encountered in our way down we should just return
 
5) Print single child nodes
6) remove leaves....remove leaf in pre area....if removed in post area all nodes will get removed
7) is tree BST......very imp (is balance tree....similar ques......either club in class, array or (change static + return something else)   )


    BSTPair isBST (Node node) {
        if(node == null) {
            BSTPair bp = new BSTPair();
            bp.min = Integer.MAX_VALUE; // note
            bp.max = Integer.MIN_VALUE;

            bp.isBST = true;
            return bp;
        }

        BSTPair lp = isBST(node.left);
        BSTPair rp = isBST(node.right);

        BSTPair mp = new BSTPair();
        mp.isBST = lp.isBST && rp.isBST && (node.val >= lp.max && node.val <=rp.min);


        if(!mp.isBST)
           return mp; // cuz if not BST then no use of finding min, max

        mp.min = Math.min(node.val, lp.min);

        mp.max = Math.max(node.val, rp.max);

        return mp;

    }

8) largest BST subtree


Binary Search Trees
-------------------------   
BST --> O(log n) (if can keep of reducing search space as in - max(), min(), find()) 
BT --> O(n)

Inorder traversal of BST gives ascending order

BST problems should always be done iteratively

1) Construct BST from given input
   - sort the input array if not already sorted
   - divide and conquer like mergesort (i.e divide in 2 almost equal halves....middle node is separate from these 2 halves) to get a balanced BST (whose height difference of left and right child is not more than 1)
   - currentNode.left = left recursive call
     currentNode.right = right recursive call
2) Remove nodes from BST (Recursive)
   - 4 cases, when the node to be removed is a .... i) 0 child node or ......ii) 1 child (L) node or.......iii) 1 child (R) node.....or iv) 2 child node (trickiest)
   - when 2 child node is to be removed, simply removing it will break the tree .....so it needs to be replaced with some other node....it can be replaced with either max of left subtree or min of right subtree....and then do not forget to remove the chosen max/min from left/right subtree respectively....and that will not be a problem as max/min can only be found at leaf nodes  

   - Recursive solution takes recursive space, iterative solution will take no extra space i.e it'll take O(1) space....That's why have attached iterative solution in Foundation 2 notes for add, delete in BST.....Iterative solution seems error prone...but try once w/o looking
   - BST problems should always be done iteratively.....Level Up 2...Tree....BST Set.....LCA in BST

3) Remove nodes from BST (Iterative)
   - use dummy, prev/parent
   - find the node with the given value (curr)
   - move the right subtree of curr to the rightmost of curr's left subtree
      - edge case: what if curr's left subtree is null
      - remember the root of this left subtree (sub)
   -  either do parent.left = sub or parent.right = sub depending on whether curr is the left or right child of parent respectively

4) Replace with sum of larger.... Imp....DIY...in both ways....LNR and RNL as well
                        A
                     /      \
                    /        \
                   /          \
                  C            B

    - For C --> A + B is larger
      For A --> B is larger
5) LCA  in a BST
    - LCA in a BT --> O(n) space + recursive space (nodeToRootPath[] required)
    - LCA in a BST --> O(1) space + recursive space
6) Print in range
7) 2 Sum BST....Very Imp....O(h) == O(log n) for a balanced BT
    - we want answer pairs in increasing order. Therefore inorder traversal of BST (Any node cannot be used as both the elements of the pair)

    - 3 approaches ............   Approach 1 has better S.C.  ................   Approach 2 has better T.C  ..........    Approach 3 --> best of both worlds...approach 1,2..........while talking about S.C. we are not including the recursive stack space required for solving the main problem, we are just talking about how much extra space is required
    - Approach 1          T.C.: O(nh),      S.C.: O(h)
         - traverse all nodes, at each node find() the complement in BST...........complement = targetSum - currentNode.data........T.C. of find() in BST is O(h) == O(log n)
    - Approach 2          T.C.: O(n),        S.C.: O(n)
         - make an arrayList by traversing all of BST....then the problem reduces to 2 Sum problem on an array which can be solved using 2 pointers (left, right)
    - Approach 3          T.C.: O(n),        S.C.: O(h) ..............Just like Approach 2 but we just avoided storing in arrayList.....next element on demand.....streaming
         - left pointer can be obtained by InorderBSTIterator, right pointer can be obtained by ReverseInorderBSTIterator......cannot use recursive stack for iterator, need manual stack ( a data structure created in heap which could maintain state till when iterator is called the next time) so that it can be controlled.....use 'state' variable to code iterative inorder traversal (Refer Generic Trees section of Foundation 2)
         - If we use morris traversal to code iterator then we can reduce the S.C. to O(1) .......... Level Up 2 - Tree - Traversal Set - leetcode 173 Binary Search Tree Iterator


HashMaps and Heaps
----------------------------
a particular data structure is unordered ==> the order of insertion is not the same as order of storing

Inbuilt HashMap functions --> getOrDefault(key, defaultValue), putIfAbsent()

putIfAbsent() doesn't overwrite unlike put()

Heap
   - PriorityQueue<Integer>pq = new PriorityQueue<>(); // min heap
   - PriorityQueue<Integer>pq = new PriorityQueue<>(Collections.reverseOrder()); // max heap 
     Alternatively for max heap
       -  PriorityQueue<Integer>pq = new PriorityQueue<>( (a,b) -> {
                return b-a;
          });
   - add(), remove() from heap --> O(log n)     peek() --> O(1)

   - HeapSort (add 1 by 1 in heap then remove 1 by 1 to get sorted order) --> T.C.: O(nlog n)          S.C.: O(n) ... There is an inplace version too
   - inplace i.e O(1) space version 
       - we don't create a separate DS (heap)
       - instead we maintain heap in given array
       - recursive downHeapify   S.C: O(log n)
       - iterative downHeapify   S.C: O(1)
   
1) k largest elements
   - Approach 1: using max heap.....O( (n+k) log n)
        - insert all elements in heap O(nlog n) time  then removal of k elements from heap in O(klog n) time
   - Approach 2: using min heap......O( (n+k) log k) .... better approach as k <= n
        - DS to store k largest should be what? we'll figure out later
        - Algo: 
            - create DS out of the first k elements (doesn't matter whether largest or not)
            - If the incoming element is better(larger) than the weakest(smallest) of the group --> welcome! && kick out the weakest one from the DS
        - How can we find the weakest one most efficiently? ---> min heap => DS should be min heap
        - initial creation of heap of k size - O(klog k)
        - if all of (n-k) elements lead to removal and addition - 2 * (n-k) * log k = O(nlog k)
        - removing the k largest elements from the min heap 1 by 1 -    k * O(1) = O(k)  

2) Sort k nearly sorted array ..... every element of the array is at max displaced k spots left or right to its position in the sorted array
   - Approach 1: sort the array in O(nlog n) time...Note we did not use the fact that "at max k displaced"
   - Approach 2: using min heap O(n log k)  .... There will be <= (k+1) elements in the heap at any point of time
        - In sorted array min most element will be at 0th index and since it cannot be displaced on left, (no space...no valid array index on left) it can only be displaced upto index (k+0) on the right....so if we consider (k+1) elements from index 0 to index k, we'll definitely get the min element ...so heap of size (k+1) is enough... once we remove an element from heap to get current min only then we should add any further element in the heap...since the number of element in the heap should not exceed (k+1) 
        - add first then remove from heap is also ok but that'll just increase heap size which is not really needed .... kyunki heap me agar zaroort se zyada elements hi rakhna hota to n element hi kyu nhi rakh liye

3) Longest consecutive sequence of elements (like 5,6,7,8..... these can occur in any order and at any index which need not necessarily be continuous indexes) - Refer Level Up 1 instead and not Foundation 2
   - fill all in hashset
   - now for each element in array
      - if it is present in hashset
         - remove it
         - keep on removing previous element if present in set
         - keep on removing next element if present in set

         - len = Math.max(len, nextE - preE - 1)

4) Implementation of PriorityQueue using heap .... Imp
   - a BT is a heap if
       -  it is a complete BT
            - before h th level, (h-1) levels should be completely filled
            - a node cannot have R child if it does not have a L child
       - all nodes satisfy heaporder property which is -  root has highest priority among root and its child subtrees
            - if L, R subtrees too satisfy heaporder property => L, R child subtrees too are heap among themselves

   - heap not stored as BT but as arraylist  cuz
       - if stored as BT adding a node will be (n) (cuz we'll have to do level order traversal)
       - traversing child to parent is not easy in BT (for upHeapify)
 
   - add(), remove() ... O(log n) ..... why so? cuz we always maintain a complete (balanced) heap .... and add/remove operations on a balanced tree are O(log n) .. like AVL(balanced BST) ...cuz only for balanced tree height of tree , h = log n  (complete --> all of previous h-1 levels are completely filled, and all levels are strictly filled from L to R. In other words there can be no R child if any L child is skipped) (balanced --> difference between height of left,right child subtrees is not more than 1) (a complete tree is always a balanced tree)
   - peek() ...O(1)


   - creation of heap (addition of n elements) can be done in 2 ways
       - when online data (data coming 1 by 1...in other words streaming)
           - each intermediate stage is heap
           - Algo
                void add(int val) {
                   data.add(val); // maintaining heap in arraylist named 'data'
                   upHeapify(data.size() - 1);
                }

       - when complete data present initially
           - Algo
                 void createHeap (int[] arr) {
                     for(int val: arr) {
                       data.add(val);
                     }
                     // downHeapify(0); // i.e. downHeapify(root) .....this is wrong
                     // for a BT to be heap left subtree and right subtree must be heap
                     // so we need to start from below
                     // as leaf nodes are already heap
                     // so we need to ensure heap from 2nd last level from right hand side

                     
                     for(int i = data.size()/2; i>=0; i--) {
                         downHeapify(i);
                     }
                 }
               
     

   - add () --> 
                - add to last of arrayList then upHeapify(idx) .... why to last ? so that operation can be done in O(1) .... here idx = last index when initial call was made
                   - upHeapify(idx) recursively works on each node in the node to root path of the added node

                - uses upHeapify
                     - when online streaming data
                     - when we use PQ provided by Java
                     - creation of heap - T.C: O(nlog n)

                - or uses downHeapify 
                     - when all the data is initially available
                     - when we create our custom heap
                     - creation of heap - T.C: O(n)

     remove() --> 
                - uses downHeapify
                - highest priority element is the only accessible element in the heap....so now when it needs to be removed, removing from beginning of arraylist will be O(n) due to shifting whereas removing from last of arrayList is O(1).
                    - For this 0th and last leaf node are swapped. which arises the need for downHeapification beginning at 0th
 
   - both upHeapify and downHeapify converts a non-heap to heap .... only their direction of movement is different

   - upHeapify (idx) - 
       - 
            void upHeapify(int idx) {

              if(idx >= 1) {
                 int pidx = (idx -1)/2; // up jana h - up to parent hi h

                 if(data.get(pidx) > data.get(idx)) {
                   swap(idx, pidx);
                   upHeapify(pidx); // if this function was for idx and since it is "up"Heapify therefore recursive call will be for parent i.e pidx               
                 }
              }
            }
 
       - Why recursive?

            2
          /   \
         5     7
        / \   /
       10  6  4   <-- new insertion: 4
       
      
      since 7 > 4 so 4, 7 will be swapped
      2 was < 7 but whether it will be less than the even lesser than 7 i.e 4 or not is not a certainty
      so we need to perform upHeapify even on the parent (pidx) and not just current node (idx)


   - downHeapify()
      - 
         void downHeapify(int idx) {
            int lcidx = 2 * idx + 1; // down jana h - down to child hi h
            int rcidx = 2 * idx + 2;


            int minidx = findMin(idx, lcidx, rcidx);
            
            if(minIdx != idx) { if parent/root is not the min
               swap(idx, minIdx);
               downHeapify(minIdx);
            }
         }

       - Why recursive?

            2                                      7 (A)                                                                       4
          /   \                                  /   \                                                                       /   \
         5     4   -- everything was > 2  ----> 5     4 (B) -- downHeapify(A) cuz everything might not be > 7 as 7 > 2 -->  5     7 ------> downHeapify(B) cuz everything might not be > 7
        / \   /                                / \   /                                                                     / \   /
       10  6  7                               10  6  2                                                                   10  6  2


      and so on
                    

5) Median Priority Queue/Find median from data stream ... instead of max/min the heap should return median (middle element) in current sorted array in O(1) time
   - Approach 1: insertion sort as it is an online algorithm....O(n^2)
   - PQ can only be min/max heap....we have to somehow adapt MPQ from a PQ
   - Internally MPQ for user = PQ1(max) + PQ2(min) ..... if MPQ = 10, 20, 30, 40, 50, 60 then PQ1 = 10, 20, 30  and PQ2 = 40, 50, 60
   - When we have to add() in MPQ how would we know whether internally we have to add in PQ1 or PQ2 ? if the incoming element is greater than peek of PQ2, then we add that element in PQ2 else PQ1
   - If we follow above we'll end up adding all elements in PQ1 itself and none in PQ2 cuz initially both of PQ1, PQ2 are empty and above comparison can only be done when PQ2 is non-empty
   - Also the size of PQ1, PQ2 should be more or less the same so that we can get median and not some random element at root of the heap
   - So whenever the size difference of PQ1, PQ2 becomes > 1, we shift 1 element between them to reduce the difference ... Imp point // easy to miss

6) Comparable vs Comparator
   - both are interfaces
   - if a class implements Comparable<T> , it has to implement the compareTo(T other) function
   - if a class implements Comparator<T> it has to implement the compare(T child, T parent) function
   - Comparator is pluggable while PQ creation unlike Comparable

   - For min heap, compareTo(T other) should be implemented like below
     int compareTo (T other) {
           return this.x - other.x;  // x is a member of T class
     }
   - For max heap, compareTo(T other) should be implemented like below
     int compareTo (T other) {
           return other.x - this.x;  // x is a member of T class
     }
   - For implementing Comparator<T> , compare() should be implemented like below
     int compare(T child, T parent) {
         return child.x - parent.x;
    }
    - When we don't know that on which basis to compare any two objects, we keep several Comparators prepared. Each comparator does comparison on basis of 1 particular thing 
    - How to use comparator??
        class StudentWeightComparator implements Comparator<Student> {
              int compare(Student s1, Student s2) {
                    return s1.wt - s2.wt; 
              }
        }
        class StudentHeightComparator implements Comparator<Student> {
              int compare(Student s1, Student s2) {
                    return s1.ht - s2.ht; 
              }
        }

         PriorityQueue<Student> pq = new PriorityQueue<>(new StudentWeightComparator());

| Feature                  | `Comparable`             | `Comparator`                      |
| ------------------------ | ------------------------ | --------------------------------- |
| Package                  | `java.lang`              | `java.util`                       |
| Method                   | `compareTo(T o)`         | `compare(T o1, T o2)`             |
| Sorting logic defined in | Class itself             | Separate class or lambda          |
| Used for                 | Natural/default ordering | Custom or multiple orderings      |
| Modifies class?          | Yes                      | No                                |
| Java 8+ convenience      | —                        | `Comparator.comparing()`, lambdas |

7) Merge K sorted lists (also in LL txt notes Foundation 1)
   - most efficient O(Nlog K) approach using heap
   - make a Pair of 
        - li (list index in lists)
        - di (data index within a particular list)
        - val

8) Implementation of HashMap
   - https://github.com/AshuOPragmatikosThrylos/LLD-Problems/tree/main/11.%20HashMap%20Implementation/code

   - HashMap --> array of LLs (like a graph, only difference being presence of a loading factor λ)
   - each cell of the above array is called a bucket
   - each node in the LL is a <key, value> pair
   - search in HM ≡ search in a specific bucket in HM.... put in HM ≡ put in a specific bucket in HM....similarly for other operations on HM
   - and time complexity for any operation on HM ≡ time complexity for that operation on 1 single bucket = O(λ) where λ = number of elements in HM (n) / number of buckets in HM or cell in array (N) = n/ N
   - we never let λ cross a particular value (threshold)....so we can say O(λ) ≡ O(constant) or O(1)
   - so average T.C. of any HM operation is O(1) but worst case is still O(n) ..... all elements of HM in 1 single bucket
   - How do we ensure λ stays under a threshhold (k) ? When λ becomes > k (why will λ change in the first place? with each insertion in HM, n increases but N doesn't change so λ increases) , we double the number of buckets and do reshuffling. This is called rehashing()......is a costly operation but its frequency decreases with each time λ crosses k....our sacrifice for a O(const) T.C.
   - How do we know which element should be placed/searched in which bucket? hashFunction(key) which returns bucketIndex
   - 1 way of implemetation of hashFunction() can be as follows
     int hashFunction(K key) {
        return Math.abs(key.hashCode()) % buckets.length;
        
        // key.hashCode() not hashCode(key).....hasCode() is a function in Object and thus all class
        // hashCode() can return -ve integer as well
    }



Graphs
----------------------------
Never forget this check ---> visit or do recursive call only if unvisited
when the graph could be disconnected, we've to always ---> loop through all vertices


- What is graph ---> G(V, E)
- What is a tree then? ---> acyclic graph with a special status node called 'root'
- Graph is implemented using
   - adjacency matrix
       - cons:
          - space wastage in case of sparse matrix
          - adding vertex is O(V^2)
       - pros:
          - whether there is an edge b/w 2 vertices - O(1)
   - adjacency list  (G = ArrayList<Edge> [V] i.e graph is array of arraylist of objects)
       - cons:
          - whether there is an edge b/w 2 vertices - O(E)

 - 
   class Edge {
      int src;
      int nbr; // neighbour
      int wt;
   }

1) has Path? (b/w src and dest vertices)
 - throuh use of visited[] current node is not allowe to be considered as neighbour of its neighbour
 - before moving to neighbour, mark current nodes as visited and explore only unvisited neighbours
 - no need to mark current node as unvisited after exploring all neighbours of current node cuz if no path exists b/w current node and dest
   ten it doesn't matter throuh which path we reach current node
2) Multisolver (ceil/floor than criteria, kth largest path)
3) get connected components
  - loops through all vertices
  - do something for each unvisited vertex
     - what something?
          - traverse the graph until no unvisited neighbour left while adding vertices in the "connected vertices" arraylist

  - when the graph could be disconnected, we've to always - loops through all vertices

4) is graph connected?
  - use "get connected components"
5) derivative of connected components
    - number of islands
    - perfect friends
6) is graph cyclic? (imp)
  - graph could be disconnected. So even if 1 component of a disconncted graph is cyclic => graph is cyclic
  - if a node is revisited it is cyclic graph
  - 
    boolean is graphCyclic (ArrayList<Edge> graph[]) {
      boolean []visited = new boolean[graph.length];
      for(int i=0; i< graph.length; i++) {
         if(!visited[i] && isComponentCyclic(graph, i, visited))
            return true;
      }
      return false;
    }

  - isComponentCyclic() can be written using dfs or bfs

7)  is graph bipartite? (very imp)
  - graph could be disconnected. So even if 1 component is not bipartite => graph is not bipartite
  - bfs to be used
  - Pair<node, level> to be pushed in queue
  - if last level and current level are not same => odd size cycle => not bipartite
      - in visited[] we store level (instead of boolean []visited)
      - last level from visited[] and current level from popping out of queue
  - if false is never returned from above => it could either be acyclic graph or even sized cycle => bipartite
  - Arrays.fill(arrayName, value) --> fills each cell of arrayName[] with 'value'

8) Spread of infection
  - 1 edge == 1 unit of time. So as we explore all nodes through edges in bfs wavefronts .... no of edges so far == time passed so far
  - if a node is already infected i.e if it is revisited
      - neither we have to increase the number of nodes infected count
      - nor we should add its neighbours again in queue
      - so just 'continue' to the next iteration
9) Dijkstra (single source shortest path ...in terms of weight not in terms of number of edges)
  - single source shortest path in terms of number of edges --> bfs
  - doesn't work when -ve weighted edges are involved
  - dijkstra's is exactly bfs with the only diff being in dijkstra's we use PQ instead of Q
  - Pair <vertex, psf, wsf> in Q
  - if already visited, continue to next iteration
  - TODO: revisit after refering level up version
  
10) Prims
  - used to find MST (Minimum Spanning Tree)
   - spanning: covers all vertices of a graph
   - tree: acyclic graph
   - MST - There might be many STs possible in a graph. The ST with the minimum total cost is called MST
  - Algos for finding MSTs - Prims, Krushkal's
  - Pair <vertex, parent, wt> in Q
+----------------------------------------------------+--------------------------------------------------+
| Prims                                              | Dijkstra                                         |
+----------------------------------------------------+--------------------------------------------------+
| 1. source need not be given                        | 1. source is given                               |
| 2. gives relative path and cost (relative from any | 2. gives absolute path (wrt source) and cost     |
| of the vertex in the partially formed ST)          |                                                  |
|                                                    |                                                  |
|                            what goes inside Q (from code perspective                                  |
|                                        there's no other diff)                                         |
+----------------------------------------------------+--------------------------------------------------+

 - TODO: revisit after refering level up version

11) Topological Sort
- applicable only for DAG (directed acylic graph)
   - TS gives and for cyclic graph too but obviously that'll be incorrect cuz in a cyclic graph there can't be any specific order
   - Kahn's algo (BFS) does not give ans for cyclic graph and gives a correct one for acyclic graph
- solved using DFS
- A process is dependent on its child => Do child first => in postorder put in stack
- Execution order is the opposite of TS which we collect in stack
- graph could be disconnected => we've to loop through all vertices
- To verify order of TS sequence --> all edges must be in same direction
- if question has DAG/dependency --> think about TS
- TODO: revisit after refering level up version

12) Iterative DFS
 - impl is just like BFS with the only diff being that in DFS stack is used instead of Q
 - stack frame created during recursive calls are limited in memory
     - Java supports only 10k recursive calls in most JVMs
 - the reference of the exteranl stack used in iterative dfs is created in stack but the actual stack is stored in heap which is not limited in space

13) get all Hamiltonian Path and Cycles
 - hamiltonian path - visits all vertices exactly once
 - hamiltonian cycle - if there is an edge between the first (passed as source parameter) and last vertex of a hamiltonian path

 - path => DFS cuz BFS grows radially
 - base case - all vertices are visited
 - HashSet over array - to efficiently find if all visited or not
 - 
   void hamiltonianPathAndCycles(ArrayList<edge> graph[], int vertex, int source, HashSet<Integer> visited, String psf) {
     if(visited.size() == graph.length - 1) { // we have already visited n-1 elements and are on nth element now
        System.out.print(psf);
        
        boolean isHCycle = false;
        
        for(Edge e: graph[vertex]) {
          if(e.nbr == source) {
             isHCycle = true;
             break;
          }
        }
        
        if(isHCycle)
          System.out.println("*");
        
        return; //backtracking - we want all paths
     }

     visited.add(vertex);

     for(Edge e: graph[vertex]) {
        if(!visited.contains(e.nbr)
            hamiltonianPathAndCycles(graph, e.nbr, source, visited, psf+" "+ e.nbr);

     }

     visited.remove(vertex); //backtracking - we want all paths
   }


   invocation --> hamiltonianPathAndCycles(graph, src, src, new HashSet<Integer>(), src);


Time and Space (Sorting)
-------------------------
1) Bubble sort....O(n^2) in best and worst
  - total n-1 passes of complete array
  - in each pass, next biggest element assumes its correct position in the right side (sorted array starts forming from right)
  - so in each pass, j can only take n-pass values (j = 0 to n-pass-1)

2) Selection sort....O(n^2) in best and worst
  - i: index for which we want correct element
    m: index of min found so far in the pass
    j: index to be compared with m (in search of min in unsorted portion)

  - at the end of each pass m, i elements are swapped
  - sorted array starts forming from left 

  - selection sort < bubble sort (number of swaps)
 
3) Insertion sort....O(n) in best, O(n^2) in worst
  - At the start of the program, 1st cell of array is assumed sorted
  - i: 1st element of unsorted portion on right (to be included in sorted portion on left)
  - if element at i is smaller than the last element of the sorted portion, swap
  - then continue compairing from the right to left to ensure proper sorted order in the sorted portion
  - Optimisation (optional): stop compairing when ( . < .)

4) Mergesort....TC: O(nlogn); SC: O(n)
-
 mid = lo + (hi-lo)/2 => divisions: [lo, mid], [mid+1, hi]
 mid = hi + (lo-hi)/2 => divisions: [lo, mid-1], [mid , hi]

- stable sorting algo - the relative order of equal elements is preserved after sorting

Example:
Input:
[(4, 'a'), (3, 'x'), (4, 'b'), (1, 'y')]
Sorted by first number (Merge Sort):
[(1, 'y'), (3, 'x'), (4, 'a'), (4, 'b')]  -->  'a' stays before 'b'


- main call and recursive call  both should return an array
- method signature should have 3 things - arr[], lo, hi

int[] mergeSort(int[] arr, int lo, int hi) {

    //base case

    int mid = ....

    int[] fsh = mergeSort(arr, lo, mid);
    int[] ssh = mergeSort(arr, mid+1, hi);
    
    return mergeTwoSortedArrays(fsh, ssh);
}

5) Partition an array.....T.C: O(n)
 - Initially we have --> (unknown)
 - In any intermediate stage we have --> (smaller or equal to the pivotValue) then (larger) then (unknown)
 - say larger starts from i and unknown starts from j index
 - We've to decide at each stage --> in which region (smaller or larger) the 1st element of unknown should be shifted

 - int partition(int[] arr, int pivotValue, int lo, int hi) --> return pivotIndex after partitioning i.e (i-1)

6) Quicksort
 - inplace algo (no new space is created)
 - T.C: avg: O(nlogn), worst: O(n^2) (when already sorted)
 - in randomised QS, we swap the pivotIndex and the lastIndex ; rest all is same afterwards
    - To find random value in a range --> Math.random() * (max - min + 1) + min
    - Math.random() returns double 
    -  
       int pivotIndex = low + (int)(Math.random() * (high - low + 1));
       swap(arr, pivotIndex, high);
 - method signature should have 3 things - arr[], lo, hi

 void quickSort(int[] arr, int lo, int hi) {
   
    // base case

    // below 2 lines for randomised QS
    // int pivotIndex = low + (int)(Math.random() * (high - low + 1));
    // swap(arr, pivotIndex, high);

    int pivot = arr[hi];
    int pi = partition(arr, pivot, lo, hi);

    quickSort(arr, lo, pi-1);
    quickSort(arr, pi+1, hi);
    
}

 - last element is chosen pivot so that it is swapped last thus making it the last element in the smaller region so that we can achieve  
   ((smaller elements) pivotElement) (larger region)

7) find kth smallest element in an array (might not be sorted)
  - QuickSelect: T.C: avg - O(n), worst - O(n^2) (Most optimal solution)
  - mostly similar to QuickSort
  - Diff: 
       - we make only 1 recursive call of quickSort() depending on whether (k-1) > pivotIndex or <
       - if == then we return pivotValue (i.e arr[hi])
  
Algorithm        | Average Case Equation              | Avg. Complexity         | Worst Case Equation           | Worst Complexity
------------------------------------------------------------------------------------------------------------------------------------------------------
Quicksort        | T(n) = 2T(n/2) + O(n)              | O(n log n)              | T(n) = T(n-1) + O(n)          | O(n^2)
Quickselect      | T(n) = T(n/2) + O(n)               | O(n)                    | T(n) = T(n-1) + O(n)          | O(n^2)


8) Count Sort...T.C: O(n+range) == O(n) if range <<< n
 - stable algo
 - can be used when limited and known range
 - Ex: cannot be applied when min = 1, max = 100000
 - Ex: scores of thousands of students where score can only be in between [0-100]

 - Algo
     - Find min = 3, max = 9, range = 9-3 = 6, size = range + 1 = 7
     - Make frequencyArray
     - Modify frequencyArray to store prefix sum
     - loop through the original array from L <--- R and 
          - place arr[i] in prefixSumArray[arr[i] - min] - 1 (cuz 0 based indexing)
          - prefixSumArray[arr[i] - min]--

9) Radix Sort
 - for lexicographical sorting
 - from LSB to MSB
 - uses count sort (stable algo)
 - Ex: 267, 358, 294 --> 294, 267, 358 --> 358, 267, 294 --> 267, 294, 358

 - Algo
   - apply countsort N no of times where N = number of digits in max in array
       - find max in array
       - 
         int exp =1;
         while (exp <= max) { // loop will run for <= 10 times as max integer in java is of 10 digits
            countSort (arr, exp);
            exp = exp * 10;
         }
     
    - prefixSumArray[arr[i] - min] in radix sort becomes --> prefixSumArray[arr[i]/exp % 10]
    - arr[i]/exp % 10 basically gives digit in exp th place

10) Sort Dates (DD-MM-YYYY) all dates fro year 0 to 2500
   - DD << MM << YYYY (significance)
   - countSort(arr, dev, mod, range)
   - 
       sortDates(arr) {
          countSort(arr, 1000000, 100, 32); // DD
          countSort(arr, 10000, 100, 13); // MM
          countSort(arr, 1, 10000, 2501); // YYYY
       }

11) sort 0, 1......in O(n) 1 pass.....use partitioning
   - Initially we have --> (unknown)
   - In any intermediate stage we have --> (0s) then (1s) then (unknown)
   - say 1s starts from i and unknown starts from j index
   - We've to decide at each stage --> in which region (0s or 1s) the 1st element of unknown should be shifted
   - loop condition: j < arr.length

12) sort 0, 1, 2
   - Initially we have --> (unknown)
   - In any intermediate stage we have --> (0s) then (1s) then (unknown) then (2s)
   - say 1s starts from i and unknown starts from j, 2s starts from k index
   - We've to decide at each stage --> in which region (0s or 1s or 2s) the 1st element of unknown should be shifted
   - loop condition: j < k
   - Initially 
        i=0, j=0 (0, 1 grows ---->)
        k = arr.length (2 grows  <----)

13) Target Sum Pair
   - Req: If ans is {(a,b), (c, d} then a<c, a<b, c<d
   - Approach
       - Arrays.sort(arr);
       - two pointers at opposite ends

14) leetcode 33 - Search Element in Rotated Sorted Array - I (array has distinct elements) (Take You Forward - Youtube)
   - application of binary search
   - identify which half is sorted
        - if(arr[lo] <= arr[mid]) => left half (from lo to mid) is sorted
        - if(arr[mid] <= arr[hi]) => right half (from mid to hi) is sorted
   - check if the target lies in the sorted half and eliminate half of the array accordingly


            // Check if left half is sorted
            if (nums[left] <= nums[mid]) { // Note: = should be handled with left half else wrong answer....alternative: use equals in both but use if-if and not if-else...if do not use = in the if-condition for right half in leetcode 81 then get TLE....conclsion: use if-if and use = in both the conditions for left and right sorted check     
                if (target >= nums[left] && target < nums[mid]) {
                    right = mid - 1; // search left half
                } else {
                    left = mid + 1; // search right half
                }
            }
            // Otherwise, right half is sorted
            else {
                if (target > nums[mid] && target <= nums[right]) {
                    left = mid + 1; // search right half
                } else {
                    right = mid - 1; // search left half
                }
            }

15) leetcode 81 - Search Element in Rotated Sorted Array - II (array can have duplicates) (Take You Forward - Youtube)
   - When elements at low, mid, hi all are same ---> we can't find which half is sorted
     Ex: 3 1 2 3 3 3 3.....lo = 0, hi = 6, mid = 3.....arr[lo] == arr[mid] == arr[hi] == 3
   - In such a case, trim down the search space if arr[mid] != target ---> li++ and hi-- 


   -  while (lo <= hi) {  // low < hi se wrong ans aata h

         int mid = 
         if (arr[mid] == target) 
            return true;

         // if flow comes here => arr[mid] != target
         if( arr[lo] == arr[mid] && arr[mid] == arr[hi]) {
            li++;
            hi--;
            continue; // easy to miss
         }

         // rest of the code same as leetcode 33
  
      } 

    - T.C: avg: O(log n)
           worst: O(n).....li++, hi-- might lead to exploring almost all the array...when the array has a lot of duplicates ..... 3 3 3 3 1 3 3 3 3

16) leetcode 153 - pivot/min in rotated sorted array ....tricky

public int findMin(int[] arr) {
  int lo = 0;
  int hi = arr.length - 1;

  int min = (int) 1e9;
  while (lo <= hi) {
    int mid = lo + (hi - lo) / 2;

    if (arr[lo] <= arr[hi]) { // not necessary; is just optimisation // when both halves are sorted

      // return arr[lo]; // wrong // easy to make mistake

      min = Math.min(min, arr[lo]);
      break; // note: in problem 15 it was continue
    }

    if (arr[lo] <= arr[mid]) {
      min = Math.min(min, arr[lo]);
      lo = mid + 1; // exclude all other elements from left half from search space // easy to miss
    }
    if (arr[mid] <= arr[hi]) {
      min = Math.min(min, arr[mid]);
      hi = mid - 1; // exclude all other elements from right half from search space // easy to miss
    }
  }

  return min;
}


17) leetcode 154 - pivot/min in rotated sorted array 2....V V Imp
- like 153 and
- shrink space when arr[lo] == arr[mid] == arr[hi]

class Solution {
  public int findMin(int[] arr) {
    int lo = 0;
    int hi = arr.length - 1;

    int min = Integer.MAX_VALUE;
    while (lo <= hi) {
      int mid = lo + (hi - lo) / 2;

      //   if (arr[lo] <= arr[hi]) { //Caution: wrong

      if (arr[lo] < arr[hi]) { // not necessary; is just optimisation  // when both halves are sorted

        // return arr[lo]; // wrong

        min = Math.min(min, arr[lo]);
        break;
      }

      // both halves sorted
      if (arr[lo] == arr[mid] && arr[mid] == arr[hi]) {
        lo++;
        hi--;
        min = Math.min(min, arr[mid]); // easy to miss
        continue;
      }

      // left half sorted
      if (arr[lo] <= arr[mid]) {
        min = Math.min(min, arr[lo]);
        lo = mid + 1;
      }

      // right half sorted
      if (arr[mid] <= arr[hi]) {
        min = Math.min(min, arr[mid]);
        hi = mid - 1;
      }
    }

    return min;
  }
}

18) how many times rotation 
 - just return index of min/pivot

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Level Up 1
------------

Stacks
-------
1) NGOR in a circular array
 -  even when all elemenents on Right are over still the ans could be on left cuz it is circular. So in NGOR replace
     - traversal from 0 to n-1 to ----> 0 to 2n-1 (can be imagined as same array twice...side by side)
     - arr[i] to ---> arr[i%n]
 - push only if i<n cuz now we're traversing till 2n-1 and the indices [n, 2n-1] do not exist
     - st.push(i%n) is wrong....no exception cuz of modulus but even the indices for which we might have found ans get pushed in stack
2) Online Stock Span
 - online: we don't get array as input but we get elements 1 by 1
 - store Pair<day, price> in stack as w r not given array of stock price....use int[] instead of Pair if readability is not a concern
 - st.push(new int[] {day, price}) --> wrong
   st.push(new int[] {day++, price}) --> correct      
   At 1st invocation of next() i.eon 0th day we see -1 in tos which is actually prev day, so ++ to get current day
3) Validate Stack Sequences - pushed[], popped[] given as input. return true if the sequences make sense.........Imp
 - Ex: pushed = [1,2,3,4,5], popped = [4,3,5,1,2]
   o/p: false (1 cannot be popped before 2)
 - 1 stack for pushed + 1 pointer on popped[]
 - Algo
    - iterate over pushed[]
       - push into stack
       - pop till tos matches popped[i]
    - if stack is empty => valid sequences
4) remove min number of paranthesis to make valid sequence
 - removing is O(n) instead we'll just not print invalid parenthesis
 - so we need to remember the indices of invalid parenthesis
 - if '(' --> push
 - if ')'
   - if tos == '(' --> pop
     else remember index (i.e  push index in stack)

 - If using Java's inbuilt Stack not allowed
   - use ArrayDeque (faster)
   - other options
      - LinkedList (unlimited memory)
      - implementing SLL --> removeLast is O(n) so not prefered
      - implementimg DLL --> time taking impl
5) Asteroids Collision.....V Imp
 - like candy crush ...cascading collapse possible => use stack
 - push asteroids[i] only when it does not get destroyed
     - definitely won't get destroyed in cases: ++, --, -+ (tos, asteroids[i])
 - only case remaining: +-
     - G, S (tos, asteroids[i]) G: greater, S: smaller --> asteroids[i] destroyed
     - ==   --> asteroids[i] destroyed and pop tos cuz it got destroyed too
     - S, G --> pop all smaller than push yourself cuz asteroids[i] won't be destroyed

    public int[] asteroidCollision(int[] asteroids) {
        Deque<Integer> stack = new ArrayDeque<>();

        for (int a : asteroids) {
            boolean destroyed = false;

            // +, -
            while (!stack.isEmpty() && stack.peekLast() > 0 && a < 0) {
                int top = stack.peekLast();
                if (Math.abs(top) < Math.abs(a)) { // S, G
                    stack.removeLast();
                    // do not break cuz check others in stack
                } else if (Math.abs(top) == Math.abs(a)) { // ==
                    stack.removeLast();
                    destroyed = true;
                    break;
                } else {
                    // G, S
                    destroyed = true;
                    break;
                }
            }
            
            // definitely: ++, --, -+
            // might be: +-
            if (!destroyed) {
                stack.addLast(a);
            }
        }
        //code 
   }

6) maximum area rectangle in histogram
 - O(n) 3 pass solution
   - width = NSOR [i] - NSOL[i] -1
 - O(n) 1 pass solution
   - write NSOR code and remember NSOL = st.peek()
   - before iterating push -1 in stack
   - since index cannot be -1 so we do not use st.size != 0 in loop but we use st.peek() != -1
     so even after iterating all n elements there could still be leftovers in stack for which NSOR = n
7) Maximal Rectangle.....V Imp
 - vary height, keep width same => at first consider only row 0, then row 0+row 1 then row 0+row 1+row 2 and so on
 - compute height[i] for all column (width kept same always)
     - Note: if the cell in the last considered row is 0 then whole height becomes 0
 - for each height[], the problem now reduces to largest area rectangle in histogram 
 - can be solved using DFS to get connected components.....wrong
   DFS can't ensure rectangle
 - might have DP solution but not optimal
8) Maximal Square
 - like maximal rectangle which uses maximum area of rectangle in histogram
 - only diff --> in place of h * w in maximum area ofrectangle in histogram --> h < w? h * h : w * w
9) Remove K Digits.....Imp....many edge cases
 - since we have to preserve relative ordering of unremoved digits => stack
 - traverse from MSB to LSB
    - keep on pushing
    - as soon as curr ele is less than tos, pop ALL greater from  stack (ofcourse only till k>0)
 - if even after traversing all characters, k!=0 ...pop till k becomes 0 // easy to miss
 - now the stack holds the reqd sequence
 - do not print leading 0s (mentioned in question) (a/c to ques o/p of 10200, 1 should be 200 and not 1020)
 - if after removing all leading 0's the ansswer sequence becomes empty string then print 0 instead of empty string // easy to miss edge case
10) Remove Duplicate Letters - DIY - if can do in 1st attempt => u r good with easy logic, hard to code ques
 - visited[] 
     - occured before on left or not (needed to exclude duplicates)
     - while popping make visited false
 - freq[] 
     - will occur again on the right or not (to ensure while popping that every letter remains at least once in the final result)
     - decrement on each visit 
 - both visited[], freq[] are required. they have different purposes
11) Trapping Rain Water
 - find water above every building and add them
 - water above a building = min(lmax, rmax) - height of building
   lmax: max height while travelling L to R
   rmax: max height while travelling R to L
 - whether rmax is the actual greatest on right of current or not is irrelevant. It's the min height that matters
    - actual greatest will be rmax or > rmax. min height will still remain the same

 - totalWater += lmax < rmax ? lmax - height[l++] : rmax - height[r--]

 - using 2 pointers.....time: O(n), space: O(1) 
     - 3 more methods; less efficient


HashMaps and Heaps
----------------------------
frequency of alphabets --> frequency array cuz limited
freq of numbers --> hashmap if range is very large or not limited

1) top k frequent elements
  - similar to k largest elements
  - make a min heap of k elements only
  - after size crosses k --> remove
  - eventually the k elements left in the minheap will be the max frequency elements (cuz min ko to hm htate ja rhe the)

  - similar problem: k closest points to origin
2)  kth smallest element in a sorted matrix
  - put 0th column in PQ initially
  - 2D index to 1D index for n * m matrix
      (r, c) --> (r * m + c)
  - 1D index to 2D index
      idx --> r = idx / m
              c = idx % m
3) Insert Delete getRandom in O(1) (easy)
  - reqd: arraylist, hashmap<value, index in list>
  - remove() is the most imp
   
4) Maximum Frequency Stack
  - Approach 1 - HashMap + PQ ...... TC: O(log n) for push, pop; SC: O(4n) (3n for Pair, n for hashmap)
      - maximum => PQ
      - frequency => frequency map
      - If there is a tie for the most frequent element, the element closest to the stacks's top is removed => remember which is inserted when => maintain index
      - Pair<val, freq, idx> in PQ
      - if on decrementing freq in freqMap it becomes 0, don't forget to remove key from freqMap

  - Approach 2 - HashMap + Stacks ...... TC: O(1) for push, pop; SC: O(2n) (n for arraylist of stacks, n for hashmap)
      - frequency => frequency map
      - maxFreq variable
      - list of stacks - ArrayList<Stack<Integer>> list
          - 1 stack per frequency
          - list.get(1) gives stack1 in which we store all val whose freq is 1
              - when the freq of val increases to 2, we don't change stack1 but we now add val in stack2
5) Trapping Rain Water 2 .... very imp
  - cannot be sole like trapping rain water 1D
     - tw += min(lmax, rmax, umax, dmax) - height[i][j] is wrong
  - fill all cells of all 4 outer walls in PQ initially and mark them as visited
  - 
        int minBoun = 0, water = 0;

        while (pq.size() != 0) {
            int idx = pq.remove();
            int i = idx / m, j = idx % m;

            // Math.max cuz if the nearer boundary is higher then it blocks the water not the farther outer boundary
            // argument minBound is from prev iteration before shrinking boundary

            minBoun = Math.max(minBoun, heightMap[i][j]);
            water += minBoun - heightMap[i][j];

            for (int d = 0; d < 4; d++) {
                int r = i + dir[d][0];
                int c = j + dir[d][1];

                // visit unvisited neighbours
                if (r >= 0 && c >= 0 && r < n && c < m && !vis[r][c]) { 
                    // shrinking boundary
                    vis[r][c] = true;
                    pq.add(r * m + c); 
                }
            }
        }
6) Swim in rising water
  - Approach 1: PQ (min heap) - single source shortest path
      - visited array required
      -  
        pq.add(0); // 1D index of (0,0)
        vis[0][0] = true;

        int waitingTime = 0;

        while (pq.size() != 0) {
            int idx = pq.remove(); // popping means new node is now visited
            
            // code for 1D to 2D index mapping

            // Note: max.....cuz whichever is more we'll have to wait at least that much time to be able to swim across
            waitingTime = Math.max(waitingTime, height); // waitingTime = current water level
            if (i == n - 1 && j == n - 1)
                break;

            // visit unvisited neighbours (in next iteration)
            for (int d = 0; d < dir.length; d++) {
                int r = i + dir[d][0];
                int c = j + dir[d][1];

                if (r >= 0 && c >= 0 && r < n && c < n && !vis[r][c]) {
                    vis[r][c] = true;
                    pq.add(r * n + c); // adding in PQ cuz i want the min one
                }
            }
        }
        return waitingTime;
 

  - Approach 2: Binary search on ans (here we've to find min time so ans is time)
      - How did we know BS can be used? 
          - "minimise the max" type of problem
              - what is the least time => find min
              - at most t => if level at two cells r not same already then to swim across need to wait till -> max(current water level, height of building)....ya to wo meri barabari kr le ya m uski barabari kr lu \
          - left and right bounded search space

      - 
         int l = grid[0][0], r = n * n -1;
         while(l <= r) {
            
            if(dfs()) { // dfs() --> does a path exist with 'mid' as waiting time
               result = m;
               r = m - 1;

            } else
               l = m + 1;
         }

7) Smallest range covering elements from k sorted lists - DIY....easy
8) IPO - Maximize final capital by choosing up to k profitable, affordable projects - given: k, initialCapital, profits[], capital[]....DIY 
    - idea: repeat k times - out of the projects that can be done in the available capital, pick the project with the max profit
    - algo
   	 - make project[i][] = capital[i] + profits[i]
         - sort on basis of capital....not necessay but to prevent checking all the projects
         - all those projects whose capital <= availableCapital ....add such projects in maxHeap so that we can get the one with the max profit
 
  
Arrays and Strings
----------------------------
>0 check is always safer than !=0 check
never do ++ or -- in if() or while() ....do it in the body {}

1) Max possible sum of i* A[i]. A[] can be rotated in any direction, any number of times....DIY
  - start with brute force ... O(n^2)
  - efficient approach ....O(1)
      - rotate by 1 and try to see how sum changed
      - this way we'll not have to actually rotate and recompute sum by traversing whole array again and again
      - sum i+1 = sum i + sum of elements - (n * A[n-i]) (rotated clockwise)
      - sum i+1 = sum i - sum of elements + (n * A[n-i]) (rotated anti-clockwise)
      - don't need to check both formulas cuz if we r rotating n times it makes no diff
2) Container with most water
  - start with brute force ... consider every possible pair of lines ... O(n^2)
  - 2 pointer approach
  - moving the pointer with the smaller height might give us maxArea
       - provided we consider the current area even before moving the pointers
  - moving the pointer with the larger height will always give smaller area as compared to current area

    public int maxArea(int[] arr) {
        int n = arr.length, maxArea = 0, i = 0, j = n - 1;
        while (i < j) {
            int w = j - i;
            maxArea = arr[i] < arr[j] ? Math.max(maxArea, arr[i++] * w) : Math.max(maxArea, arr[j--] * w);
        }

        return maxArea;
    }
 

| Problem                        | What you maximize     | Depends on       | Typical Approach  |
| ------------------------------ | --------------------- | ---------------- | ----------------- |
| Container With Most Water      | Water between 2 lines | Two chosen lines | Two pointers      | Area=(j-i)×min(height[i],height[j])
| Trapping Rain Water            | Total trapped water   | All bar heights  | Two pointers      | wateri​=min(leftMaxi​,rightMaxi​)-height[i]
| Largest Rectangle in Histogram | Area under bars       | Width per bar    | Stack             | Area=height[i]×(rightLimiti​-leftLimiti​-1) ... leftLimit[i] = index of the first smaller bar to the left of i


Pattern for occurances in a window questions (sliding window)

   - `count` variable to differentiate between the two states of the window - when window has and does not have something
   - freqMap[] required

   - while(ei < n) {

         if(condition on freq of ei) {
            update count
            adjust freqMap
            increment ei

         }

         while(condition on count) {

            if(condition on freq of si) {
               update count
               adjust freqMap
               increment si
            }
         }

    }


3) Fruit into baskets (essentially same as longest substring with at most 2 distinct characters)  .... DIY
  - instead of 
       moving the start pointer in such problems which deal with occurances in a window, (inefficient)
    we can 
       remember indices of characters (efficient)

4) Minimum Window Substring....DIY good question
5) Max number of vowels in a substring of given length.....DIY

6) Longest substring with exactly k unique characters
7) number of Subarrays with K different integers....V Imp
   - understand how is it different from above substring problem
       - we can't just increase answerCount in place of len = Math.max(len, ei-si)
       - cuz there may be multiple valid subarrays ending at current ei (not just one)
       - ex: [1, 2, 1], k=2 ---> there are 2 answer subarrays ending at the last 1 .... [1, 2, 1], [2, 1]

   - ans = atMostKDistnct(arr, k) - atMostKDisinct(arr, k-1)
   - NOTE: we don't increment count by 1 in atMost() but by ei-si

Extra: (num & 1) != 0 => num is odd

8) number of non empty subarrays - given a binary array and a sum = `goal` ....Binary Subarrays With Sum
   - ans = atMost(tar) - atMost(tar-1)
   - why such a formula? cuz tar will be achieved by adding 1 again and again....basically this is no of 1 problem disguised as sum problem
9) Max consecutive ones in a binary array
   - apart from the sliding window approach as used for above other problems
       slightly optimised approach --> when a 0 is encountered do si = ei after ei++
10) Max consecutive ones if can flip at most one 0....Imp
   - apart from the sliding window approach as used for above other problems
       slightly optimised approach -->  when encounter 0 adjust firstZexoIndex (index of previous zero) cuz at most one 0 is allowed in the window
   - follow up Q: can flip at most k 0s.....replace count == 2 (or count > 1) with count > k


Pattern (occurance in a window) end

prefix sum is making new sum by adding in old sum
alternative but not efficient way is ....each time on addition of new element, adding all the elements to get sum

11) number of subarray such that  Subarray sum divisible by k......V Imp
   - need to find cumulative sum (prefix sum) at  each element
   - for a subarray AB to be divisible by k
       (b-a) % k == 0
     => b % k == a % k == r
     => if the remainders at two points are equal, then the subarray between those points will be our desired subarray
   - how man such subarrays?
      - find remCount[r] for each r (r can range from 0 to k)
      - for each remCount[r] = n, ans += nC2
   - how to find nC2 easily?
      - nC2 = (n*(n-1)))/(2*1) = 1 + 2 + .....+ n
      - so at each stage add remCount[r] in ans then increment remCount[r] by 1
   - don't forget to initialise remCount[0] = 1 (if not then we would have lost one subarray from 0th index to the element where r == 0 has been found for the first time cuz ans+= remCont[0] would be ans += 0)


b: sum from 0th element to Bth element
a: sum from 0th element to Ath element

12) longest subarray with sum divisible by k
  - almost same as prev prob
  - rem[0] = -1 // storing first index  of remainder and not count
  - distinction of "remainder not found yet" cannot be != -1 as that is the index for remainder 0
     - so use != -2
     - initialise rem[i] with -2 except for 0th index
 
13) number of subarrays with equal 1s and 0s.....Imp
  - replace 0 with -1
  - prefix sum

  - our desired subarray is the subarray between two points with same sum

  - increase count by value of key = sum in map
  - update map
  - NOTE: initialise count = 1 for sum = 0 for the first occurance of sum = 0

  - Follow up Q: longest subarray....initialise with index = -1 for sum = 0; store index of first occurance of key = sum in map...if 2nd, 3rd...occurance don't store ----> putIfAbsent() can be used

14) Sliding Window Maximum (also in Stacks and Queues Foundation 1) ..... V Imp
  - Brute force - TC: O(nk); SC: O(1)
  - PQ - TC: O(nlogn); SC: O(n) // using java's heap
  - TreeMap - TC: O(nlog k); SC: O(k) // TreeMap eagerly deletes, so size ≤ k; PQ deletes lazily, so size can grow to n

  - less intuitive solutions
      - Stack - TC: O(n); SC: O(n) // idea: last NGOR in the window is the max
      - Queue (most optimal) - TC: O(n); SC: O(k) // idea: maintain decreasing monotonic queue // intuition got after PQ soln: Bigger element dominates all smaller left elements → discard smaller ones → remaining decreasing deque’s front is max
    
 
 - HashMap is not ordered
   TreeMap is HashMap but ordered
 - TreeMap is nothing but balanced BST
 - Every operation in a BST is O(height) and if it is balanced i.e for TreeMap it height = log n
 - In TreeMap duplicates are compressed using frequency
 - lastKey(), firstKey(), floorKey(), ceilingKey() all in O(log n)

 - Monotonic = always moves in one direction (never zig-zags)
     - Monotonic increasing → each next value ≥ previous
     - Monotonic decreasing → each next value ≤ previous



15) Maximum Sum Subarray.......V V V Imp
  - Approach 1 O(n^3) --> O(n^2) to make subarrays * O(n) to calculate sum for each subarray
  - Approach 2 O(n^2) --> O(n^2) to make subarrays + O(n) to make prefixSum[] (subArraySum = prefixSum[end + 1] - prefixSum[start])
  - Approach 3 Divide & Conquer O(nlogn)
     - either in left part or in right part or across mid
     - calculate max prefix sum 
         - from mid to si
         - and from mid to ei
         - and add them
  - Approach 4 Kadanes O(n)
     - currentSum, globalSum
     - 2 types of Kadanes
         - which does not return negative sum but return 0
             - start over when currentSum becomes <=0 i.e set currentSum to 0 cuz no point i cosidering subarray with sum 0 and negative sum will only decrease incoming sum
             - things to remember
                - check: csum <= 0
                - csi = i + 1
             -  
                                    public int[] maxSubArray(int[] arr) {
                                        int gsum = 0, csum = 0, gsi = 0, gei = 0, csi = 0;

                                        for (int i = 0; i < arr.length; i++) {
                                            int ele = arr[i];
                                            csum += ele;

                                            if (csum > gsum) {
                                                gsum = csum;
                                                gsi = csi;
                                                gei = i;
                                            }

                                           if (csum <= 0) { // note this is after comparison with gsum; reset krne se pehle consider for gsum
                                                csum = 0;
                                                csi = i + 1; // skip negative sum subarray
                                           }
                                       }
                                      return new int[] {gsum, gsi, gei};
                                  }

         - which returns negative sum
             - we move forward with csum being whatever is higher among the updated csum (csum+ele) or the ele itself
             - things to remember
                - check: ele >= csum
                - csi = i
                - gsum is initialised with -(int) 1e9 unlike type 1 kadanes
             -   
                                    public int[] maxSubArray(int[] arr) {
                                        int gsum = -(int)1e9, csum = 0, gsi = 0, gei = 0, csi = 0;

                                        for (int i = 0; i < arr.length; i++) {
                                            int ele = arr[i];
                                            csum += ele;

                                           if (ele >= csum) { // note this is before comparison with gsum; why before? You must pick the better path before deciding if this newly chosen path is the global winner
                                                csum = ele;
                                                csi = i; // ele will be > old csum + ele only when old csum was < 0 .... so skipping negative sum subarray means skipping till old csum
                                           }

                                            if (csum > gsum) {
                                                gsum = csum;
                                               gsi = csi;
                                               gei = i;
                                            }
                                       }
                                      return new int[] {gsum, gsi, gei};
                                  }
             - Think of each index as a "checkpoint":
                                         - At every index:
                    - Choose path A: continue old sum
                    - Choose path B: start fresh at current element
                - You must pick the better path before deciding if this newly chosen path is the global winner

Extra: kadanes doesn't work for > or <. Just adding < or > won't give correct results

16) max absolute sum of any subarray....easy DIY
   - approach 1: double kadanes
      - ans = max (maximised +ve sum, - numerically maximised -ve sum)
      - for maximised +ve sum, whenever sum becomes < 0, start over (i.e make sum = 0)
      - for numerically maximised -ve sum, whenever sum becomes > 0, start over (i.e make sum = 0)
   - approach 2: max sum - min sum
      - How did we arrive at ans = max sum - min sum?
          - maximise (b-a) = maximise b - minimise a

              b: sum from 0th element to Bth element
              a: sum from 0th element to Ath element

17) k concatenation max sum ..........Imp but not easy   to arrive at solution 
 - ans = (int) Math.max(kadanesSum, maxPrefixSum + maxSuffixSum + (k-2) * arraySum)
 - before that do --> arraySum = arraySum < 0 ? 0 : arraySum
 - even before that do --> if (k==1) return kadanesSum
 - explanation
    - k == 1 --> understandabe
    - k == 2 (kadanes of 2) --> 
        - either ans will be in 1st array --> kadanesSum
        - or across 2 arrays --> maxPrefixSum + maxSuffixSum
        - so ans = whichever is max among above 2
    - k > 2
        - arraySum >= 0 --> 
              [———–[#####]———–] .....(k-2) arrays in between.....[———–[#####]———–]

                        ans =                  <---------------------------------------------------------->

        - arraySum < 0 --> 
             - considering even 1 copy of the complete array will only decrese the sum
             - so ans is the same as when k==2 i.e kadanes of 2

18) Max sum rectangle in a 2D matrix - kinda similar to Maximal Rectangle (Stacks)
 - vary height, keep width same => at first consider only row 0, then row 0+row 1 then row 0+row 1+row 2 and..... then row 1, then row 1 + row 2, then row 1 + row 2 + row 3....and so on 
 - compute height[i] for all column (width kept same always)
 - for each height[], the problem now reduces to kadanes of 1D array
---------------------------------------------------------------------------------
19) 209 Min Size Subarray sum ...min size of subarray whose sum >= target
 - subarray sum => use prefix sum (sum += ele)
    - subarray sum = prefixSum[ei] - prefixSum[l-1]
 - if the prefix sum >= target (=> subarray(0, ei) has sum >=target), keep on (while loop) moving si pointer forward so that we can get min length
    - but as we move si forward due to monotonically increasing nature of prefix sum of positive integers only array, subarray sum will decrease (don't forget to adjust it i.e subarray sum contained in prefixSum). So eventually we will come out of while loop when prefixSum is no longer >= target

20) 862 Shortest Subarray with Sum at Least K - exactly same problem as above just that now we can have negative integers as well
  - since we have negative integers as well therefore moving si to right might not decrease sum always. Therefore two pointer approach will not work
  - maintain monotonic increasing in deque
     - keep different directions for popping to make queue monotonically increasing and for popping to make >=k condition valid --> invalid

21) 363 Max Sum Of Recatangle No Larger Than K
 - subproblem - Subarray sum at most k .... Imp
    - use TreeSet to find ceiling
 - like "Max sum rectangle in a 2D matrix"
 - consider all possible rectangles like above problem
 - make 2D --> 1D
 - apply actual problem on 1D array
    - use prefix sum for that


19 --> sliding window
20 --> Monotonic Deque
21 --> TreeSet
---------------------------------------------------------------------------------
22) Number of submatrices that sum to target.....DIY
 - subproblem - Subarray sum equals target .... Imp
 - like "Max sum rectangle in a 2D matrix"
 - consider all possible rectangles like above problem
 - make 2D --> 1D
 - apply actual problem on 1D array
    - use prefix sum for that

23) Rabbits in Forest ..... good question....only person with clarity of thought can do it in 1 attempt
 - 
    public int numRabbits(int[] answers) {
        int []kitneLogonNeSameJawabDiya = new int[1000]; // Constraint in ques: 0 <= answers[i] < 1000 // <key, value> == <jawab, kitneLogonNeSameJawabDiya>

        int ans = 0;

        for(int kitneAadmiThe : answers) {
            int ekThaliKChatteBatte = kitneAadmiThe + 1;

            // min poocha h..isliye baar baar count ni krna
            // jb jawab pehli bar sunne ko mila sirf tbhi count krna h

            if(kitneLogonNeSameJawabDiya[kitneAadmiThe] == 0)
                ans += ekThaliKChatteBatte;

            kitneLogonNeSameJawabDiya[kitneAadmiThe]++;    

            if(kitneLogonNeSameJawabDiya[kitneAadmiThe] == ekThaliKChatteBatte)
                kitneLogonNeSameJawabDiya[kitneAadmiThe] = 0;// thali puri hui, ab same jawab next time would mean new thali
        }
        return ans;
        
    }
 
  
Searching and Sorting (includes Application of binary search)
----------------------------

while (l<=r) has to be accompanied by l++ and r--
while(l<r) has to be accompanied by l++, r or l, r-- .....if e use l<=r and do not increment or decrement in either body of if or else then we'll get TLE

(observed in multiple problems....in this section observed in "Koko eatin bananas")
 

1) Search Insert Position (no duplicates)
 - approach 1
     - exactly BS code
     - except return si and not -1 if not found
 - approach 2 - just before the insert position

2)  Search Insert Position (with duplicates)
 - just before the insert position
 - 
              public static int searchInsert(int[] arr, int data) {
                  int n = arr.length, si = 0, ei = n - 1;
                  while (si <= ei) {
                     int mid = (si + ei) / 2;
                     if (arr[mid] <= data)
                         si = mid + 1; 
                     else
                         ei = mid - 1;
                  } 

                 int insertPos = si;
                 int lastIndex = si - 1;

                 return (lastIndex >= 0 && arr[lastIndex] == data) ? lastIndex : insertPos;
            }

3) Find closest number in sorted array
 - approach 1: min abs diff while iterating over array - O(n)
 - approach 2: whichever among ceil or floor is closest - O(logn)
    - for ceil and floor refer foundation 1
 - approach 3 (easiest to code) - O(logn)
   - standard BS code
   - when si no longer <= ei, then whichever is closer among si or ei is our ans
      - (data - arr[ei] < arr[si] - data)? arr[ei] : arr[si]

4) see how leetcode 74 is different from leetcode 240
 - leetcode 74 can be solved in O(m+n) and O(log(mn))
 - leetcode 240 can be solved only in O(m+n)

5) count inversions in an array (two elements a[i] and a[j] form an inversion if a[i] > a[j] and i<j)
 - divide and conquer
 - ans = f(left) + f(right) + count across array
 - count across array can only be computed when the left, right subarrays are sorted
 - so algo: mergeSort
    - diff
       - return count from f(left), f(right)
       - when merging the sorted subarrays, compute count across them

6) leetcode 1 - Two sum - given: unsorted array, target, has no duplicates
 - 
    public int[] twoSum(int[] arr, int target) {
        HashMap<Integer, Integer> map = new HashMap<>();
    
        for (int i = 0;i<arr.length; ++i)
        {
           int complement = target - arr[i];
           if(map.containsKey(complement))
               return new int[]{i, map.get(complement)};
            else
               map.put(arr[i],i);
        }
        return new int[0];
    }

 - similar question: 2 sum count....DIY
   - Q: A[i] + B[j] == target; find count of (i,j)

7) k sum
 - kSum is dependent on (k-1)Sum
 - 
    public List<List<Integer>> kSum(int[] arr, int target, int k, int si, int ei) {
        if (k == 2)
            return twoSum(arr, target, si, ei);

        List<List<Integer>> ans = new ArrayList<>();

        for (int i = si; i < ei;) {            // note : not <=ei; n increemnt in the loop itself
            List<List<Integer>> smallAns = kSum(arr, target - arr[i], k - 1, i + 1, ei);  // note: starts from (i+1); in twoSum() we do while(si<ei) not while(si <=ei)

            prepareAns(ans, smallAns, arr[i]);

     // note: below done cuz arr[si] can occur multiple times...similar thing we've done inside twoSum for both si, ei to handle duplicates
     // below is to skip all duplicates
            i++;
            while (i < ei && arr[i] == arr[i - 1])
                i++;
        }

        return ans;
    }
    
8)  leetcode 454 - 4 sum 2 - 4 sum count
 - A[i] + B[j] + C[k] + D[l] == target
 - 
    int fourSumCount(int[] nums1, int[] nums2, int[] nums3, int[] nums4) {
        HashMap<Integer, Integer> map = new HashMap<>();
        for (int e1 : nums1)
            for (int e2 : nums2)
                map.put(e1 + e2, map.getOrDefault(e1 + e2, 0) + 1);

        int count = 0, target = 0;
        for (int e1 : nums3)
            for (int e2 : nums4)
                if (map.containsKey(target - e1 - e2))
                    count += map.get(target - e1 - e2);

        return count;
    }

9) Koko eating bananas
 - Binary search on ans (here k)
 - How did we know BS can be used? 
     - "minimise the max" type of problem
         - find min k (in question) => minimise
         - have to eat all bananas => keep speed as max as possible
     - left and right bounded search space
         - 1 <= piles[i] <= 10^9
     - constraint
         - within h hours

 - 
         int l = 1, r = (int)1e9;
         while(l <= r) {
            int k = si + (ei-si)/2

            if(!possibleToEat()) {
               si = k + 1;

            } else
               ei = k - 1;
         }
 -

    boolean isPossibleToEat(int[] arr, int eatingSpeed, int hour) {
        int hr = 0;
        for (int i = arr.length - 1; i >= 0; i--) {
            hr += Math.ceil(arr[i] / (eatingSpeed * 1.0)); // Note: ceil
            if (hr > hour)
                return false;
        }

        return true;
    } 

 10) Maximum Area serving cake 
 - Binary search on ans (here area of cake)
 - How did we know BS can be used? 
     - "minimise the max" type of problem
         - determine largest area (in question) => maximise
         - each guest should get a piece => keep the area as min as possible
     - left and right bounded search space
         - lower bound - (lower bound of radii[i])^2
         - upper bound - (upper bound of radii[i])^2
     - constraint
         - total number of guests
 - stopping condition 
    - while(si <= ei) // wrong cuz area is in floating this 2 values might never be equal...infinite loop
    - while(ei-si > 1e-5) // question says we want precision in ans till 4 decimal places... so when the diff becomes even smaller than 0.00001 we need to stop
 - go to higher area --> ei = mid
   go to lesser area --> si = mid (adding or subtracting 1e-5 doesn't make sense)

11) Capacity to ship packages within D days
 - si = maxWeight
   ei = sumOfAllWeights
 - TODO: revisit after studying DP...see notes I pencil in level up 1 copy

12) Minimise max distance to gas station
 - while((ei-si) > 1e-6)...cuz mentioned in question: answers within 10^-6 of the actual answer will be accepted
 - if gas stations are added at every x distance, then b/w stations a->b ...(b-a)/x stations can be added
    - noOfGasStations += (arr[i] - arr[i-1])/distance;

13) Median of two sorted arrays  ... V V Imp and Hard
 - Brute Force 1 - iterate over both arrays and merge and store the sorted array....TC: O(m+n), SC: O(m+n)
 - Brute Force 2 - iterate over both arrays and merge and instead of storing - return N/2 th, or mean of N/2 th and (N/2 + 1) th elements on the fly
 - Optimal (Binary Search)
    - ensure BS on smaller size array
        - if(n1>n2) if(n1>n2) return findMedianSortedArrays(b, a);
        - Why? 
           - if n1> n2 and if we apply BS on a[]
             since aleft oscillates between [0, n1-1] (aleft = (lo +hi)/2 on a[] of size n1)
             => aleft can take value n1-1 
             => bleft could be negative (since te/2 will be between [n1/2, n1)) and negative index is absurd
    - hi != n1-1 but hi = n1 initially cuz all of a[] could be less than all of b[] so segregation point will be after a[]
                     |
         . . . alm1  |_  al . . .       a[]
         . . . . blm1  | bl .           n[]
                       |
                  segregation point

         alm1 should be < bl
         blm1 should be < al
    -
  public double findMedianSortedArrays(int[] a, int[] b) {
        int n1 = a.length, n2 = b.length;
        if(n1>n2) return findMedianSortedArrays(b, a);
        
        int lo = 0, hi = n1, te = n1 + n2;
        
        while(lo <= hi)
        {
            int aleft = (lo + hi) / 2;
            // int bleft = (te + 1) / 2 - aleft;
            int bleft = te/2 - aleft;
            
            int alm1 = (aleft == 0) ? Integer.MIN_VALUE : a[aleft-1];
            int al = (aleft == n1) ? Integer.MAX_VALUE : a[aleft];
            int blm1 = (bleft == 0) ? Integer.MIN_VALUE : b[bleft-1];
            int bl = (bleft == n2) ? Integer.MAX_VALUE : b[bleft];
            
            if(alm1 <= bl && blm1 <= al)
            {
                double median = 0.0;
                
                if(te % 2 == 0)
                {
                    int lmax = Math.max(alm1, blm1);
                    int rmin = Math.min(al, bl);
                    median = (lmax + rmin) / 2.0;
                }
                else
                {
                    // int lmax = Math.max(alm1, blm1);
                    int rmin = Math.min(al,bl);
                    // median = lmax;
                    median = rmin;
                }
                
                return median;
            }
            else if(alm1 > bl)
                hi = aleft - 1;
            else if(blm1 > al)
                lo = aleft + 1;
        }
        return 0.0;
    }

14) length of Longest Increasing Subsequence (LIS)
 - O(n^2) DP solution
 - O(nlog n) BS solution
   - we've to maintain a list to store "LIS so far"
   - inermediate LIS values will always be increasing but they may not always form a subsequece cuz of replacements; so BS solution doesn't work for printing LIS
   - we can use BS to find insertPosition() of incoming element cuz LIS so far (i.e. intermediate LIS) is obviously sorted
   - algo: if insertPosition is outside the "LIS so far" i.e (n-1) + 1 = n => length of LIS will increase
   

    int computeLIS(int[] nums) {
        List < Integer > list = new ArrayList < > ();

        for (int num: nums) {

            int pos = insertPosition(tails, num);

            if (pos == list.size()) {
                list.add(num);

            } else {

                list.set(pos, num); // replace; A smaller value at that position allows more future incoming numbers to be larger, increasing LIS potential...but it might not always be smaller right? yes but no worries cuz it still doesn't change length of "LIS so far"

            }

        }
        return list.size();
    }

    int insertPosition(List < Integer > list, int target) {
        int si = 0, ei = list.size() - 1;

        while (si <= ei) {

            int mid = (si + ei) /2;
            int val = list.get(mid);

            if (val <= target) {
                si = mid + 1;
            } else {
                ei = mid - 1;
            }
        }

        int insertPos = si;

        // below code prevents duplicates in ans
            int lastIndex = insertPos - 1;
            if (lastIndex >= 0 && list.get(lastIndex) == target) {
                return lastIndex;
            }
        

        return insertPos;
    }
   

| Method                          | Time            | Gives Length?                 | Gives LIS Sequence? |
| --------------------------------| --------------- | ------------------------------| ------------------- |
| DP (n²)                         | O(n²)           | ✔                             | ✔                  |
| Binary Search (basic)           | O(n log n)      | ✔                             | ❌                 |
| Binary Search + tracking arrays | O(n log n)      | ✔                             | ✔                  |

 
15) Find k closest elements to X in sorted array (X might not be in array)
 - PQ solution O(nlogk) - <ele, |X-ele|> in k size maxheap (sorted property not utilised)
 - BS solution O(log n + k) (same TC whether we want duplicate in ans or not)

    List < Integer > findClosestElements(int[] arr, int k, int x) {
        int n = arr.length;

        // Binary search to locate the best starting point for the k-window
        int left = 0, right = n - k - 1;

        while (left <= right) {
            int mid = (left + right) / 2;

            if (x - arr[mid] > arr[mid + k] - x)
                left = mid + 1;
            else
                right = mid - 1;
        }


        List < Integer > ans = new ArrayList < > ();
        for (int i = left; i < left + k; i++)
            ans.add(arr[i]);

        // ===== remove duplicates =====
        // Not using HashSet to save O(k) space

        // List<Integer> filtered = new ArrayList<>();
        // int prev = Integer.MIN_VALUE;
        // for (int num : ans) { 
        //     if (num != prev)
        //         filtered.add(num);
        //     prev = num;
        // }
        // return filtered;


        return ans; // include duplicates
    }


--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Level Up 2
------------



level up 1 --> 133
level up 2 --> 150
level up 3 --> 141
level up 4 --> 117



30 turns per completely free full day......speed
roughly 730 turns (Foundation 1,2 + Level Up 1,2,3,4)

obviously full free day to phir nhi milega
therefore for revising foundaton 1,2 + level Up 1,2,3,4 ---> 730/15 = 49 days required.....roughly 2 months